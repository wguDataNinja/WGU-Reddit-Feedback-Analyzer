#docs/Catalog_Overview.md.


# ğŸ“š WGU Catalog Overview

ğŸ“… Last Updated: 2025-07-04  
ğŸ›  Maintainer: [Buddy]  
ğŸ”’ Status: V10 Locked â€” Clean Baseline

---

## ğŸ¯ Project Purpose

This module extracts structured academic data from WGU's institutional catalogs (2017â€“2025) for use in downstream NLP, classification, and time-series analysis. It powers course code lookup, college-level classification, and institutional growth tracking within the broader **WGU Reddit Monitoring Capstone** project.

---

## ğŸ“¥ Catalog Download + Parse Pipeline

This pipeline downloads and processes all WGU catalogs from 2017â€“2025 using a versioned, patchable system.

### ğŸ—‚ï¸ Source Collection

- **`institutional-catalog.html`**  
  â¤· Manual snapshot of the WGU Institutional Catalog page  
- **`extract_catalog_links.py`**  
  â¤· Parses snapshot â†’ outputs `catalog_links.txt`

### ğŸ“¦ Download Plan & Validation

- **`parse_and_rename_catalogs.py`**  
  â¤· Builds `catalog_download_plan.csv` from URLs using regex + normalized naming  
- **`catalog_download_patch.csv`**  
  â¤· Optional manual patching for missed or malformed files  
- **`download_from_plan.py`**  
  â¤· Downloads PDFs â†’ `raw/`, normalized as `catalog_YYYY_MM.pdf`  
- **`verify_catalog_downloads.py`**  
  â¤· Checks for expected catalogs by month â†’ flags gaps

### ğŸ§¾ Parsing PDFs to Text

- **`plumber_parse_all_pdfs.py`**  
  â¤· Uses `pdfplumber` to convert PDFs â†’ `.txt` in `plumber_parsed/`  
- **`plumber_parse_single_pdf.py`**  
  â¤· Used for debugging individual catalogs  

---

## ğŸ§  Scraper Architecture â€” V10 Baseline

All scraping logic is built from scratch under V10. No legacy PyPDF2 outputs or mixed helpers are used. Parsing is clean, testable, and versioned.

### âœ… Key Guarantees

- Trusted input: only `.txt` from `pdfplumber`
- No legacy merges (v5â€“v9 ignored)
- All schema quirks and fixes logged in `catalog_schema_notes_v10.md`
- All regex patterns explicitly reviewed
- Fails on ambiguity â€” never guesses College/Degree headers

### ğŸ“‚ Folder Structure

WGU_catalog/
â”œâ”€â”€ catalogs/
â”‚   â”œâ”€â”€ raw/                  # PDFs
â”‚   â”œâ”€â”€ plumber_parsed/       # Clean .txt
â”œâ”€â”€ helpers/
â”‚   â”œâ”€â”€ college_snapshots_v10_seed.json
â”‚   â”œâ”€â”€ degree_snapshots_v10.json
â”‚   â”œâ”€â”€ catalog_schema_notes_v10.md
â”‚   â””â”€â”€ â€¦
â”œâ”€â”€ scripts/                  # Only _v10 scripts
â”œâ”€â”€ notebooks/                # Only _v10 notebooks
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ program_names/
â”‚   â”œâ”€â”€ raw_course_rows/
â”‚   â”œâ”€â”€ mappings/
â”‚   â”œâ”€â”€ flat/
â”‚   â””â”€â”€ â€¦
â””â”€â”€ docs/
â””â”€â”€ Catalog_Overview.md

---

## ğŸ“Š Capstone Integration â€” NLP & Classification

### Use Case

This catalog module supports the capstone project:

**â€œWGU Reddit Monitoring Pipeline with Sentiment Analysis and NLPâ€**

### Connected Pipeline Steps

1. **Extract course codes** from post text using `Cxxxx` identifiers  
2. **Map course codes** to College and Degree using the parsed catalog JSONs  
3. **Classify posts** by College (e.g., IT, Health) based on course mapping  
4. **Detect drift** in program names and catalog structure using time-series

### Example: Institutional Growth Tracking

You can visualize department expansion using parsed snapshots.

```python
# program_counts_by_year.csv â†’ output from snapshot extract

year,college,num_programs
2020,College of IT,12
2021,College of IT,15
...

Use this to create plots of College growth, track naming changes, or describe structural drift in your final paper.

â¸»

ğŸ“Œ Standing Truths
	â€¢	Course rows only parsed inside valid Degree blocks
	â€¢	Program Outcomes and trailing Certificates are fenced and isolated
	â€¢	Spillover text (e.g., Observations, Assessment Notes) is not merged
	â€¢	All anomalies logged separately
	â€¢	College/Degree changes across time tracked in snapshots

â¸»

ğŸš§ Future Work
	â€¢	Build course_index_v10.json with full College â†’ Degree â†’ Course chains
	â€¢	Normalize Course Codes to detect duplicate rows (by CU / Term)
	â€¢	Add visualization of catalog-level shifts (e.g., name changes, program churn)
	â€¢	Possibly integrate claude_catalog_tracking_system.md if schema expansion is needed

â¸»

âœ… Status

V10 is locked and verified. Parsing is ready.
All helpers are versioned. Drift is logged. Output is auditable.

ğŸ” Trusted Input: plumber_parsed/*.txt  
ğŸ§  Clean JSON: helpers/ + outputs/  
ğŸ“˜ Notes: docs/Catalog_Overview.md, helpers/catalog_schema_notes_v10.md


â¸»


