we are scraping the WGU catalog in a jupyter notebook.

We begin:

import os
import sys
from pathlib import Path

# Point to your project root
PROJECT_ROOT = Path("/Users/buddy/Desktop/WGU-Reddit/WGU_catalog")
sys.path.insert(0, str(PROJECT_ROOT))

# Import modules
from lib.config import *
from lib.anchors import *

config and anchors are:

# lib/config.py

from pathlib import Path
import json

# Project root
BASE_DIR = Path(__file__).parent.parent

# Inputs
TEXT_DIR       = BASE_DIR / "data" / "raw_catalog_texts"
SHARED_DIR     = BASE_DIR / "shared"

# Outputs (all under /WGU_catalog/outputs)
OUTPUTS_DIR            = BASE_DIR / "outputs"
HELPERS_DIR            = OUTPUTS_DIR / "helpers"
PROGRAM_NAMES_DIR      = OUTPUTS_DIR / "program_names"
RAW_ROWS_OUTPUT_DIR    = OUTPUTS_DIR / "raw_course_rows"
ANOMALY_DIR            = OUTPUTS_DIR / "anomalies"

# Final CSV outputs
COURSES_FLAT_CSV          = OUTPUTS_DIR / "courses_flat_v10.csv"
COURSES_WITH_COLLEGE_CSV  = OUTPUTS_DIR / "courses_with_college_v10.csv"

# Generated helper outputs
SECTION_INDEX_PATH         = HELPERS_DIR / "sections_index_v10.json"
DEGREE_SNAPSHOTS_OUT_FILE  = HELPERS_DIR / "degree_snapshots_v10_seed.json"
COURSE_INDEX_PATH          = HELPERS_DIR / "course_index_v10.json"

# Shared input files
SNAPSHOT_COLLEGES_PATH     = SHARED_DIR / "college_snapshots.json"
DEGREE_DUPLICATES_FILE     = SHARED_DIR / "degree_duplicates_master.json"

# Default test input
TEST_FILE = TEXT_DIR / "catalog_2017_01.txt"

# Ensure required output directories exist
for d in [OUTPUTS_DIR, HELPERS_DIR, PROGRAM_NAMES_DIR, RAW_ROWS_OUTPUT_DIR, ANOMALY_DIR]:
    d.mkdir(parents=True, exist_ok=True)

# Preloaded shared data
with open(SNAPSHOT_COLLEGES_PATH, "r", encoding="utf-8") as f:
    COLLEGE_SNAPSHOTS = json.load(f)
    "2017-01": [
        "College of Business",
        "College of Health Professions",
        "College of Information Technology",
        "Teachers College"
    ],
with open(DEGREE_DUPLICATES_FILE, "r", encoding="utf-8") as f:
    DEGREE_DUPLICATES = json.load(f)


# anchors.py
import re

# Anchors
ANCHOR_CCN_HEADER = re.compile(r"CCN.*Course Number", re.IGNORECASE)
ANCHOR_COURSE_CODE = re.compile(r"^[A-Z]{2,4}\s+\d{4}")
ANCHOR_COURSES_SECTION_BREAK = re.compile(r"^Courses", re.IGNORECASE)
ANCHOR_PROGRAM_OUTCOMES = re.compile(r"^Program Outcomes$", re.IGNORECASE)
ANCHOR_SCHOOL_OF = re.compile(r"^School of ", re.IGNORECASE)
ANCHOR_FOOTER_COPYRIGHT = re.compile(r"©", re.IGNORECASE)
ANCHOR_FOOTER_TOTAL_CUS = re.compile(r"Total CUs", re.IGNORECASE)

# Filters
PROGRAM_TITLE_EXCLUDE_PATTERNS = re.compile(r"^(Steps|[0-9]|[•\-])")

# Course row patterns
PATTERN_CCN_FULL = re.compile(
    r'^([A-Z]{2,5})\s+(\d{1,4})\s+([A-Z0-9]{2,5})\s+(.+?)\s+(\d+)\s+(\d+)$'
)
PATTERN_CODE_ONLY = re.compile(
    r'^([A-Z0-9]{1,6})\s+(.+?)\s+(\d+)\s+(\d+)$'
)
PATTERN_FALLBACK = re.compile(
    r'^(.+?)\s+(\d+)\s+(\d+)$'
)

# Registered collections
ANCHORS = {
    "CCN_HEADER": ANCHOR_CCN_HEADER,
    "COURSE_CODE": ANCHOR_COURSE_CODE,
    "COURSES_SECTION_BREAK": ANCHOR_COURSES_SECTION_BREAK,
    "PROGRAM_OUTCOMES": ANCHOR_PROGRAM_OUTCOMES,
    "SCHOOL_OF": ANCHOR_SCHOOL_OF,
    "FOOTER_COPYRIGHT": ANCHOR_FOOTER_COPYRIGHT,
    "FOOTER_TOTAL_CUS": ANCHOR_FOOTER_TOTAL_CUS
}

FILTERS = {
    "PROGRAM_TITLE_EXCLUDE_PATTERNS": PROGRAM_TITLE_EXCLUDE_PATTERNS
}

COURSE_PATTERNS = {
    "CCN_FULL": PATTERN_CCN_FULL,
    "CODE_ONLY": PATTERN_CODE_ONLY,
    "FALLBACK": PATTERN_FALLBACK
}


We define these helper functions at the top of the notebook

def extract_catalog_date(file_name: str) -> str:
    parts = file_name.replace(".txt", "").split("_")[1:]
    return f"{parts[0]}-{parts[1]}"

def pick_snapshot(date_str: str, snapshot_dict: dict) -> str:
    versions = sorted(snapshot_dict.keys())
    chosen = None
    for v in versions:
        if v <= date_str:
            chosen = v
    if not chosen:
        raise ValueError(f"No snapshot available for {date_str}")
    return snapshot_dict[chosen]


