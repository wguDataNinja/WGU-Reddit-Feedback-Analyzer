Absolutely ‚Äî here‚Äôs a comprehensive, step-by-step guide summarizing everything you‚Äôve done so far. This can serve as documentation or a passalong reference for restructuring your notebook cleanly from top to bottom.

‚∏ª

üßæ WGU Reddit Course Mention Detection ‚Äì Full Notebook Guide

This notebook processes Reddit posts to identify references to WGU course codes ‚Äî including common variations like missing prefixes (e.g., ‚Äú214‚Äù instead of ‚ÄúC214‚Äù). It includes filtering, highlighting, and previewing matches for manual review.

‚∏ª

üìÅ 1. Load Required Data

Files:
	‚Ä¢	course_mappings.csv: Contains all WGU course metadata.
	‚Ä¢	Reddit post data: Stored in a df DataFrame (with title and selftext columns).

Load course metadata:

import pandas as pd
from pathlib import Path
import json

# Load course mapping file
course_path = Path("/Users/buddy/Desktop/WGU-Reddit/data/course_mappings.csv")
course_df = pd.read_csv(course_path)

# Extract number-only versions of course codes
course_df['course_number'] = course_df['course_code'].str.extract(r'(\d{3,4})')
unique_numbers = course_df['course_number'].dropna().unique()


‚∏ª

üßπ 2. Preprocess Reddit Posts

Combine title and selftext into one field:

# Assumes df is your posts DataFrame
df['combined_text'] = df['title'].fillna('') + ' ' + df['selftext'].fillna('')

This ensures downstream processing works even if one of the fields is empty.

‚∏ª

üîç 3. Detect Number-Only Matches

Compile regex from known course numbers:

import re

number_pattern = r'\b(' + '|'.join(re.escape(num) for num in unique_numbers) + r')\b'

Match numbers only when full course code wasn‚Äôt already matched:

def find_number_only_match(text, matched_codes):
    if not isinstance(text, str) or matched_codes:
        return None
    found = re.findall(number_pattern, text)
    return list(set(found)) if found else None

df['number_only_matches'] = df.apply(
    lambda row: find_number_only_match(row['combined_text'], row.get('matched_course_codes')), axis=1
)


‚∏ª

üö´ 4. Filter Out False Positives

Define centralized filter logic:

def is_false_positive(match, text, match_start):
    pre_context = text[max(0, match_start - 5):match_start + 1]
    post_context = text[match_start:match_start + 5]

    # Exclude monetary values like $400
    if '$' in pre_context:
        return True

    # Exclude percentages like 100%
    if '%' in post_context:
        return True

    return False


‚∏ª

‚úÇÔ∏è 5. Extract Snippets With Context

Get ~10 characters before/after each number:

def extract_snippets(text, matches, context=10):
    if not isinstance(text, str) or not matches:
        return []

    snippets = []
    for match in matches:
        for m in re.finditer(rf'\b({re.escape(match)})\b', text):
            if is_false_positive(match, text, m.start()):
                continue
            start = max(m.start() - context, 0)
            end = min(m.end() + context, len(text))
            snippet = text[start:end].replace('\n', ' ')
            snippets.append(f"...{snippet}...")

    return snippets

Apply to all rows:

number_only_posts = df[df['number_only_matches'].notna()].copy()

number_only_posts['snippets'] = number_only_posts.apply(
    lambda row: extract_snippets(row['combined_text'], row['number_only_matches']), axis=1
)


‚∏ª

‚úèÔ∏è 6. Highlight Matches in Snippets

Add HTML <mark> tags:

def highlight_in_snippet(snippet, matches):
    if not isinstance(snippet, str) or not matches:
        return snippet
    for match in matches:
        snippet = re.sub(rf'\b({re.escape(match)})\b', r'<mark>\1</mark>', snippet)
    return snippet

Apply highlighting:

number_only_posts['highlighted_snippets'] = number_only_posts.apply(
    lambda row: [highlight_in_snippet(snip, row['number_only_matches']) for snip in row['snippets']],
    axis=1
)


‚∏ª

üí° 7. Display Results (Minimal Context Only)

Render with scrollable HTML output:

from IPython.display import display, HTML

highlighted_df = number_only_posts.explode('highlighted_snippets')[['highlighted_snippets']]
highlighted_df = highlighted_df.rename(columns={'highlighted_snippets': 'Context (Highlighted)'})

html_table = highlighted_df.to_html(index=False, escape=False)

display(HTML(f"""
<h3>Number-Only Course Mentions ‚Äì Highlighted Context</h3>
<div style='max-height: 500px; overflow-y: auto; border: 1px solid #ccc; padding: 10px'>
{html_table}
</div>
"""))


‚∏ª

üß≠ Next Steps / Optional Improvements
	1.	Add More Filters
	‚Ä¢	Fractions like 722/750 (but allow 405/406)
	‚Ä¢	Ranges like 100-200
	‚Ä¢	Very common unrelated numbers (like 100)
	2.	Map matches back to course names
Use course_df to look up full course info (code + name) from number-only matches.
	3.	Tag match source
Track whether the match was from title, selftext, or both.
	4.	Export results
Save filtered highlights for review or dashboarding.

‚∏ª

current problem:

Here‚Äôs a clear, detailed summary of the current task, the approach we‚Äôve taken, and the persistent issue ‚Äî written for the next AI or developer to pick up from here:

‚∏ª

üìå Goal

We are analyzing Reddit posts to identify and highlight course codes from Western Governors University (WGU). The course codes follow specific formats like:
	‚Ä¢	C123, D456 (most common)
	‚Ä¢	Occasionally others like QHT1, QGT1 (not currently targeted)

The objective is to:
	1.	Detect all course-like codes in post titles and selftexts
	2.	Classify them as either mapped (present in a course_mappings.csv) or unmapped
	3.	Highlight all occurrences of these codes in:
	‚Ä¢	The post title
	‚Ä¢	Selected context from selftext (~50 characters around each match)
	4.	Display:
	‚Ä¢	Post ID
	‚Ä¢	Highlighted Title
	‚Ä¢	Highlighted Selftext Snippet
	‚Ä¢	List of all matched codes

Mapped codes are highlighted with <mark>, and unmapped ones with <mark style='background-color:#c7f8c7'>.

‚∏ª

‚úÖ What‚Äôs Working
	‚Ä¢	The regex detection in a standalone debug cell (Cell 6) reliably identifies all valid course-like codes.
	‚Ä¢	The classification into mapped and unmapped works correctly.
	‚Ä¢	The basic logic for extracting post metadata and course codes is intact.

‚∏ª

‚ùå What‚Äôs Not Working

The highlighting logic in Cell 5 fails to highlight all matched course codes in the actual post display, even when the debug cell confirms they are present.

Specifically:
	‚Ä¢	In post 1k1uj23, the debug output correctly identifies codes like C721, C717, etc., as matched and mapped.
	‚Ä¢	But in the Cell 5 output table, those codes do not appear highlighted in either the title or selftext snippets, or are inconsistently shown.

‚∏ª

üîÅ Approaches Attempted
	1.	Simple re.sub replacement
	‚Ä¢	Worked for isolated matches but skipped duplicates or overlaps.
	2.	Placeholder injection with string replace()
	‚Ä¢	Replaced only exact matches with casing issues.
	‚Ä¢	Failed when multiple instances of the same course existed (e.g., C721 repeated).
	3.	Improved placeholder strategy using re.sub(..., flags=re.IGNORECASE)
	‚Ä¢	Inserted unique placeholders (__HIGHLIGHT_C721__)
	‚Ä¢	Replaced placeholders afterward with <mark> tags
	‚Ä¢	Still, highlighting failed for some or all occurrences.
	4.	Context snippet extraction with re.finditer(..., flags=re.IGNORECASE)
	‚Ä¢	This part worked in isolation for detecting and rendering snippets.
	‚Ä¢	However, actual highlighting within the full post text remains unreliable in the display output.

‚∏ª


# Course Code Detection Algorithm - Development Guide

## üéØ Requirements

### Core Functionality
1. **Pattern Detection**: Find all `[CD]\d{3}` patterns in Reddit posts
2. **Source Separation**: Check title and selftext separately
3. **Classification**: Categorize codes as mapped (in course_mappings.csv) or unmapped
4. **Context Display**: Show minimal context around each code occurrence
5. **Human Verification**: Enable quick visual inspection of detection accuracy

### Output Requirements
- **Total counts**: Overall detection statistics
- **Mapped codes**: Codes present in course_mappings.csv
- **Unmapped codes**: Valid D/C format but not in mappings
- **Context snippets**: ~20 chars before/after each code
- **Source identification**: Whether code found in title vs selftext
- **Minimal output**: Jupyter-friendly, concise display

---

## üí° Proposed Solutions

### **Solution 1: Simple Counter Approach** ‚≠ê (Recommended)
```python
# 5-line solution
pattern = r'\b([CD]\d{3})\b'
title_codes = df['title'].str.findall(pattern, flags=re.IGNORECASE).explode()
text_codes = df['selftext'].str.findall(pattern, flags=re.IGNORECASE).explode()
mapped = set(course_df['course_code'].str.upper())
print(f"Title: {len(title_codes)} | Text: {len(text_codes)} | Mapped: {len(title_codes[title_codes.isin(mapped)])} | Unmapped: {len(title_codes[~title_codes.isin(mapped)])}")
```

**Pros**: Ultra-concise, immediate results, clear separation
**Cons**: No context, no individual post inspection

### **Solution 2: Context Snippet Function**
```python
def show_code_context(text, code, context=20):
    matches = [(m.start(), m.end()) for m in re.finditer(rf'\b{code}\b', text, re.IGNORECASE)]
    return [text[max(0,s-context):e+context] for s,e in matches]

# Usage: show_code_context("I'm taking C721 and C722", "C721", 10)
# Output: ["'m taking C721 and C7"]
```

**Pros**: Shows exact context, reusable function
**Cons**: Still requires iteration logic

### **Solution 3: DataFrame Explode Method**
```python
# Detect and explode all codes with source tracking
df_codes = df.assign(
    title_codes=df['title'].str.findall(pattern, flags=re.IGNORECASE),
    text_codes=df['selftext'].str.findall(pattern, flags=re.IGNORECASE)
).melt(id_vars=['post_id'], value_vars=['title_codes', 'text_codes'],
       var_name='source', value_name='codes').explode('codes').dropna()

# Quick classification
df_codes['mapped'] = df_codes['codes'].str.upper().isin(mapped_codes)
print(df_codes.groupby(['source', 'mapped']).size())
```

**Pros**: Pandas-native, clean aggregation, source separation
**Cons**: More complex for beginners

### **Solution 4: Debug-Focused Sampler**
```python
def quick_code_check(df, sample_size=5):
    codes_found = []
    for _, row in df.sample(sample_size).iterrows():
        for source, text in [('title', row['title']), ('text', row['selftext'])]:
            if pd.isna(text): continue
            for match in re.finditer(pattern, text, re.IGNORECASE):
                code = match.group(1).upper()
                start, end = match.span()
                context = text[max(0,start-15):end+15]
                codes_found.append({
                    'post_id': row['post_id'],
                    'source': source,
                    'code': code,
                    'context': context,
                    'mapped': code in mapped_codes
                })
    return pd.DataFrame(codes_found)

# One-liner execution
quick_code_check(df, 10)
```

**Pros**: Perfect for debugging, shows everything needed, sampling reduces noise
**Cons**: Random sampling might miss edge cases

### **Solution 5: Hybrid Summary + Detail**
```python
# Part 1: Quick Stats (2 lines)
codes = df['title'].str.cat(df['selftext'], sep=' ').str.findall(pattern, flags=re.IGNORECASE).explode()
print(f"Total: {len(codes)} | Mapped: {codes.isin(mapped).sum()} | Unmapped: {(~codes.isin(mapped)).sum()}")

# Part 2: Show unmapped only (for human review)
unmapped = codes[~codes.isin(mapped)].value_counts()
print(f"Unmapped codes: {unmapped.to_dict()}")

# Part 3: Context for specific code (on demand)
def show_contexts(code):
    return df[df['title'].str.contains(code, case=False, na=False)]['title'].tolist()[:3]
```

**Pros**: Modular, quick overview + deep dive capability
**Cons**: Requires multiple steps

---

## üèÜ Recommendation: **Solution 4** (Debug-Focused Sampler)

### Why This Solution:
1. **Perfect for development**: Shows exactly what you need to verify the algorithm
2. **Jupyter-friendly**: Clean DataFrame output, easy to inspect
3. **Comprehensive**: Code, context, source, classification all in one view
4. **Sampling**: Reduces noise while covering diverse cases
5. **Actionable**: Immediately see if detection is working correctly

### Implementation:
```python
# One function, one call, complete verification
def verify_course_detection(df, course_mappings, sample_size=10):
    pattern = r'\b([CD]\d{3})\b'
    mapped_codes = set(course_mappings['course_code'].str.upper())

    results = []
    for _, row in df.sample(sample_size).iterrows():
        for source, text in [('title', row['title']), ('selftext', row['selftext'])]:
            if pd.isna(text): continue
            for match in re.finditer(pattern, str(text), re.IGNORECASE):
                code = match.group(1).upper()
                start = match.start()
                context = text[max(0, start-20):start+len(code)+20]
                results.append({
                    'post_id': row['post_id'],
                    'source': source,
                    'code': code,
                    'context': f"...{context}...",
                    'mapped': '‚úì' if code in mapped_codes else '‚úó'
                })

    result_df = pd.DataFrame(results)
    if len(result_df) > 0:
        print(f"üìä Sample Results: {len(result_df)} codes found")
        print(f"‚úì Mapped: {(result_df['mapped'] == '‚úì').sum()}")
        print(f"‚úó Unmapped: {(result_df['mapped'] == '‚úó').sum()}")
        return result_df[['post_id', 'source', 'code', 'mapped', 'context']]
    else:
        print("No codes found in sample")
        return pd.DataFrame()

# Usage: verify_course_detection(df, course_df, 15)
```

### Expected Output:
```
üìä Sample Results: 23 codes found
‚úì Mapped: 18
‚úó Unmapped: 5

   post_id source code mapped                    context
0  1k1uj23  title C721      ‚úì  ...I'm taking C721 this semester...
1  1k1uj23   text D456      ‚úó  ...completed D456 last month and...
2  1k2abc4  title C949      ‚úì  ...failed C949 need advice...
```

# Course Code Detection Algorithm - Development Guide

## üéØ Requirements

### Core Functionality
1. **Pattern Detection**: Find all `[CD]\d{3}` patterns in Reddit posts
2. **Source Separation**: Check title and selftext separately
3. **Classification**: Categorize codes as mapped (in course_mappings.csv) or unmapped
4. **Context Display**: Show minimal context around each code occurrence
5. **Human Verification**: Enable quick visual inspection of detection accuracy

### Output Requirements
- **Total counts**: Overall detection statistics
- **Mapped codes**: Codes present in course_mappings.csv
- **Unmapped codes**: Valid D/C format but not in mappings
- **Context snippets**: ~20 chars before/after each code
- **Source identification**: Whether code found in title vs selftext
- **Minimal output**: Jupyter-friendly, concise display

---

## üí° Proposed Solutions

### **Solution 1: Simple Counter Approach** ‚≠ê (Recommended)
```python
# 5-line solution
pattern = r'\b([CD]\d{3})\b'
title_codes = df['title'].str.findall(pattern, flags=re.IGNORECASE).explode()
text_codes = df['selftext'].str.findall(pattern, flags=re.IGNORECASE).explode()
mapped = set(course_df['course_code'].str.upper())
print(f"Title: {len(title_codes)} | Text: {len(text_codes)} | Mapped: {len(title_codes[title_codes.isin(mapped)])} | Unmapped: {len(title_codes[~title_codes.isin(mapped)])}")
```

**Pros**: Ultra-concise, immediate results, clear separation
**Cons**: No context, no individual post inspection

### **Solution 2: Context Snippet Function**
```python
def show_code_context(text, code, context=20):
    matches = [(m.start(), m.end()) for m in re.finditer(rf'\b{code}\b', text, re.IGNORECASE)]
    return [text[max(0,s-context):e+context] for s,e in matches]

# Usage: show_code_context("I'm taking C721 and C722", "C721", 10)
# Output: ["'m taking C721 and C7"]
```

**Pros**: Shows exact context, reusable function
**Cons**: Still requires iteration logic

### **Solution 3: DataFrame Explode Method**
```python
# Detect and explode all codes with source tracking
df_codes = df.assign(
    title_codes=df['title'].str.findall(pattern, flags=re.IGNORECASE),
    text_codes=df['selftext'].str.findall(pattern, flags=re.IGNORECASE)
).melt(id_vars=['post_id'], value_vars=['title_codes', 'text_codes'],
       var_name='source', value_name='codes').explode('codes').dropna()

# Quick classification
df_codes['mapped'] = df_codes['codes'].str.upper().isin(mapped_codes)
print(df_codes.groupby(['source', 'mapped']).size())
```

**Pros**: Pandas-native, clean aggregation, source separation
**Cons**: More complex for beginners

### **Solution 4: Debug-Focused Sampler**
```python
def quick_code_check(df, sample_size=5):
    codes_found = []
    for _, row in df.sample(sample_size).iterrows():
        for source, text in [('title', row['title']), ('text', row['selftext'])]:
            if pd.isna(text): continue
            for match in re.finditer(pattern, text, re.IGNORECASE):
                code = match.group(1).upper()
                start, end = match.span()
                context = text[max(0,start-15):end+15]
                codes_found.append({
                    'post_id': row['post_id'],
                    'source': source,
                    'code': code,
                    'context': context,
                    'mapped': code in mapped_codes
                })
    return pd.DataFrame(codes_found)

# One-liner execution
quick_code_check(df, 10)
```

**Pros**: Perfect for debugging, shows everything needed, sampling reduces noise
**Cons**: Random sampling might miss edge cases

### **Solution 5: Hybrid Summary + Detail**
```python
# Part 1: Quick Stats (2 lines)
codes = df['title'].str.cat(df['selftext'], sep=' ').str.findall(pattern, flags=re.IGNORECASE).explode()
print(f"Total: {len(codes)} | Mapped: {codes.isin(mapped).sum()} | Unmapped: {(~codes.isin(mapped)).sum()}")

# Part 2: Show unmapped only (for human review)
unmapped = codes[~codes.isin(mapped)].value_counts()
print(f"Unmapped codes: {unmapped.to_dict()}")

# Part 3: Context for specific code (on demand)
def show_contexts(code):
    return df[df['title'].str.contains(code, case=False, na=False)]['title'].tolist()[:3]
```

**Pros**: Modular, quick overview + deep dive capability
**Cons**: Requires multiple steps

---

## üèÜ Recommendation: **Solution 4** (Debug-Focused Sampler)

### Why This Solution:
1. **Perfect for development**: Shows exactly what you need to verify the algorithm
2. **Jupyter-friendly**: Clean DataFrame output, easy to inspect
3. **Comprehensive**: Code, context, source, classification all in one view
4. **Sampling**: Reduces noise while covering diverse cases
5. **Actionable**: Immediately see if detection is working correctly

### Implementation:
```python
# One function, one call, complete verification
def verify_course_detection(df, course_mappings, sample_size=10):
    pattern = r'\b([CD]\d{3})\b'
    mapped_codes = set(course_mappings['course_code'].str.upper())

    results = []
    for _, row in df.sample(sample_size).iterrows():
        for source, text in [('title', row['title']), ('selftext', row['selftext'])]:
            if pd.isna(text): continue
            for match in re.finditer(pattern, str(text), re.IGNORECASE):
                code = match.group(1).upper()
                start = match.start()
                context = text[max(0, start-20):start+len(code)+20]
                results.append({
                    'post_id': row['post_id'],
                    'source': source,
                    'code': code,
                    'context': f"...{context}...",
                    'mapped': '‚úì' if code in mapped_codes else '‚úó'
                })

    result_df = pd.DataFrame(results)
    if len(result_df) > 0:
        print(f"üìä Sample Results: {len(result_df)} codes found")
        print(f"‚úì Mapped: {(result_df['mapped'] == '‚úì').sum()}")
        print(f"‚úó Unmapped: {(result_df['mapped'] == '‚úó').sum()}")
        return result_df[['post_id', 'source', 'code', 'mapped', 'context']]
    else:
        print("No codes found in sample")
        return pd.DataFrame()

# Usage: verify_course_detection(df, course_df, 15)
```

### Expected Output:
```
üìä Sample Results: 23 codes found
‚úì Mapped: 18
‚úó Unmapped: 5

   post_id source code mapped                    context
0  1k1uj23  title C721      ‚úì  ...I'm taking C721 this semester...
1  1k1uj23   text D456      ‚úó  ...completed D456 last month and...
2  1k2abc4  title C949      ‚úì  ...failed C949 need advice...
```
current notebook:


# Cell 1: Load Reddit posts with subreddit name

import pandas as pd
from utils.db_connection import get_db_connection

# Connect and load selected fields
conn = get_db_connection()
query = """
SELECT p.post_id, p.title, p.selftext, s.name AS subreddit_name
FROM posts p
LEFT JOIN subreddits s ON p.subreddit_id = s.subreddit_id
"""
df = pd.read_sql(query, conn)
conn.close()

# Show total and preview
print(f"Total posts loaded: {len(df):,}")
df.head(1)


# Cell 2: Load course mappings and college keywords

import json
import pandas as pd
from pathlib import Path
from IPython.display import Markdown, display

# File paths
course_path = Path("/Users/buddy/Desktop/WGU-Reddit/data/course_mappings.csv")
keyword_path = Path("/Users/buddy/Desktop/WGU-Reddit/data/college_keywords.json")

# Load and display course mappings
course_df = pd.read_csv(course_path)
print("course_mappings.csv:")
display(course_df.head())

# Load and pretty-print college keywords
with open(keyword_path) as f:
    keyword_dict = json.load(f)

md_lines = ["**college_keywords.json:**\n"]
for college, keywords in keyword_dict.items():
    keyword_str = ", ".join(keywords)
    md_lines.append(f"**{college}**  \n{keyword_str}\n")

display(Markdown("\n".join(md_lines)))

# Cell 4: Define function to filter posts by course code

def filter_posts_by_course(posts_df, course_codes):
    """Filter posts containing any of the given course codes."""
    pattern = r'\b(' + '|'.join(re.escape(code) for code in course_codes if pd.notna(code)) + r')\b'
    combined_text = posts_df['title'].str.cat(posts_df['selftext'], sep=' ', na_rep='')
    match_series = combined_text.str.extract(pattern, expand=False)
    filtered_df = posts_df.copy()
    filtered_df['course_match'] = match_series
    return filtered_df[filtered_df['course_match'].notnull()]


    cell 5 is the problem:

    # Cell 5: Detect, classify, and highlight all course code matches across Reddit posts

from IPython.display import HTML, display, Markdown
import re

# Normalize course codes from mapping
mapped_codes = set(code.strip().upper() for code in course_df['course_code'].dropna())
generic_code_pattern = r'\b([CD]\d{3})\b'

# --- Detect all course-like codes ---
def detect_all_course_codes(posts_df):
    combined_text = posts_df['title'].fillna('').str.upper() + ' ' + posts_df['selftext'].fillna('').str.upper()
    matches = combined_text.str.findall(generic_code_pattern)
    result = posts_df.copy()
    result['matched_course_codes'] = matches
    return result[result['matched_course_codes'].apply(lambda x: len(x) > 0)]

filtered_df = detect_all_course_codes(df).copy()

# Classify course codes
def split_course_matches(matches):
    mapped = [c for c in matches if c in mapped_codes]
    unmapped = [c for c in matches if c not in mapped_codes]
    return mapped, unmapped

filtered_df[['mapped', 'unmapped']] = filtered_df['matched_course_codes'].apply(
    lambda codes: pd.Series(split_course_matches(codes))
)

# --- Highlighting helpers using placeholders ---
def highlight_all_occurrences(text, mapped, unmapped):
    if not isinstance(text, str):
        return text

    # Temporary replacements using case-insensitive regex
    all_codes = sorted(set(mapped + unmapped), key=len, reverse=True)
    placeholder_map = {}

    for code in all_codes:
        placeholder = f"__HIGHLIGHT_{code}__"
        placeholder_map[placeholder] = {
            'code': code,
            'mapped': code in mapped
        }
        # Insert placeholder using regex, ignore case
        text = re.sub(rf'\b{re.escape(code)}\b', placeholder, text, flags=re.IGNORECASE)

    # Replace placeholders with <mark> tags
    for placeholder, info in placeholder_map.items():
        code = info['code']
        if info['mapped']:
            replacement = f"<mark>{code}</mark>"
        else:
            replacement = f"<mark style='background-color:#c7f8c7'>{code}</mark>"
        text = text.replace(placeholder, replacement)

    return text

# --- Extract snippets with correct multi-match highlighting ---
def extract_snippets_all(text, mapped, unmapped):
    if not isinstance(text, str):
        return ""
    text_upper = text.upper()
    codes = sorted(set(mapped + unmapped), key=len, reverse=True)
    snippets = []
    for code in codes:
        style = 'background-color:#c7f8c7' if code in unmapped else ''
        for m in re.finditer(rf'\b{re.escape(code)}\b', text_upper):
            start = max(m.start() - 50, 0)
            end = min(m.end() + 50, len(text))
            raw_snip = text[start:end]
            highlighted = re.sub(
                rf'\b({re.escape(code)})\b',
                rf"<mark style='{style}'>\1</mark>",
                raw_snip,
                flags=re.IGNORECASE
            )
            snippets.append("..." + highlighted + "...")
    return " ".join(snippets)

# --- Apply highlighting ---
filtered_df['highlighted_title'] = filtered_df.apply(
    lambda row: highlight_all_occurrences(row['title'], row['mapped'], row['unmapped']), axis=1
)
filtered_df['highlighted_snippet'] = filtered_df.apply(
    lambda row: extract_snippets_all(row['selftext'], row['mapped'], row['unmapped']), axis=1
)

filtered_df = filtered_df.drop_duplicates(subset='post_id')

# --- Count posts with mapped vs unmapped codes ---
mapped_post_count = (filtered_df['mapped'].apply(len) > 0).sum()
unmapped_post_count = (filtered_df['unmapped'].apply(len) > 0).sum()

# --- Display summary and table ---
display(Markdown(
    f"### Posts with Course Code Mentions: {len(filtered_df):,}  \n"
    f"**Posts containing mapped course codes:** {mapped_post_count:,}  \n"
    f"**Posts containing unmapped course-like codes:** {unmapped_post_count:,}"
))

result_table = filtered_df[['post_id', 'highlighted_title', 'highlighted_snippet', 'matched_course_codes']].copy()
result_table.columns = ['Post ID', 'Title (Highlighted)', 'Self-text Snippet (Highlighted)', 'All Course Matches']

scrollable_output = (
    result_table.style
        .hide(axis='index')
        .set_properties(**{
            'text-align': 'left',
            'white-space': 'normal',
            'max-width': '600px'
        })
        .to_html(escape=False)
)

display(HTML(f"<div style='max-height: 600px; overflow-y: auto'>{scrollable_output}</div>"))

