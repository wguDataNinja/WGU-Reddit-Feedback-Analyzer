{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7555862-aaff-4c17-bad0-0978e7bd9976",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '✅' (U+2705) (1520350041.py, line 91)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 91\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m[V10] College snapshots loaded and snapshot picker ready. ✅\u001b[39m\n                                                              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid character '✅' (U+2705)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# anchors_and_patterns.py\n",
    "\n",
    "import re\n",
    "\n",
    "# Anchors\n",
    "ANCHOR_CCN_HEADER = re.compile(r\"CCN.*Course Number\", re.IGNORECASE)\n",
    "ANCHOR_COURSE_CODE = re.compile(r\"^[A-Z]{2,4}\\s+\\d{4}\")\n",
    "ANCHOR_COURSES_SECTION_BREAK = re.compile(r\"^Courses\", re.IGNORECASE)\n",
    "ANCHOR_PROGRAM_OUTCOMES = re.compile(r\"^Program Outcomes$\", re.IGNORECASE)\n",
    "ANCHOR_SCHOOL_OF = re.compile(r\"^School of \", re.IGNORECASE)\n",
    "ANCHOR_FOOTER_COPYRIGHT = re.compile(r\"©\", re.IGNORECASE)\n",
    "ANCHOR_FOOTER_TOTAL_CUS = re.compile(r\"Total CUs\", re.IGNORECASE)\n",
    "\n",
    "# Filters\n",
    "PROGRAM_TITLE_EXCLUDE_PATTERNS = re.compile(r\"^(Steps|[0-9]|[•\\-])\")\n",
    "\n",
    "# Course row patterns\n",
    "PATTERN_CCN_FULL = re.compile(\n",
    "    r'^([A-Z]{2,5})\\s+(\\d{1,4})\\s+([A-Z0-9]{2,5})\\s+(.+?)\\s+(\\d+)\\s+(\\d+)$'\n",
    ")\n",
    "PATTERN_CODE_ONLY = re.compile(\n",
    "    r'^([A-Z0-9]{1,6})\\s+(.+?)\\s+(\\d+)\\s+(\\d+)$'\n",
    ")\n",
    "PATTERN_FALLBACK = re.compile(\n",
    "    r'^(.+?)\\s+(\\d+)\\s+(\\d+)$'\n",
    ")\n",
    "\n",
    "# Registered\n",
    "ANCHORS = {\n",
    "    \"CCN_HEADER\": ANCHOR_CCN_HEADER,\n",
    "    \"COURSE_CODE\": ANCHOR_COURSE_CODE,\n",
    "    \"COURSES_SECTION_BREAK\": ANCHOR_COURSES_SECTION_BREAK,\n",
    "    \"PROGRAM_OUTCOMES\": ANCHOR_PROGRAM_OUTCOMES,\n",
    "    \"SCHOOL_OF\": ANCHOR_SCHOOL_OF,\n",
    "    \"FOOTER_COPYRIGHT\": ANCHOR_FOOTER_COPYRIGHT,\n",
    "    \"FOOTER_TOTAL_CUS\": ANCHOR_FOOTER_TOTAL_CUS\n",
    "}\n",
    "\n",
    "FILTERS = {\n",
    "    \"PROGRAM_TITLE_EXCLUDE_PATTERNS\": PROGRAM_TITLE_EXCLUDE_PATTERNS\n",
    "}\n",
    "\n",
    "COURSE_PATTERNS = {\n",
    "    \"CCN_FULL\": PATTERN_CCN_FULL,\n",
    "    \"CODE_ONLY\": PATTERN_CODE_ONLY,\n",
    "    \"FALLBACK\": PATTERN_FALLBACK\n",
    "}\n",
    "\n",
    "print(\"Anchors & Patterns loaded.\")\n",
    "\n",
    "Anchors & Patterns loaded.\n",
    "\n",
    "\"\"\"\n",
    "================================================================\n",
    "Scraper_V10 — Load College Snapshots (Canonical Order)\n",
    "----------------------------------------------------------------\n",
    "Loads:\n",
    "  - college_snapshots.json → trusted order of Colleges per catalog date.\n",
    "Utility:\n",
    "  - pick_snapshot(catalog_date) → picks snapshot version.\n",
    "Fails if:\n",
    "  - No snapshot version found <= catalog date.\n",
    "----------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "# === Path to trusted College snapshot ===\n",
    "SNAPSHOT_COLLEGES_PATH = \"../WGU_catalog/helpers/college_snapshots.json\"\n",
    "\n",
    "with open(SNAPSHOT_COLLEGES_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    college_snapshots = json.load(f)\n",
    "\n",
    "def pick_snapshot(date_str: str, snapshot_dict: dict) -> list:\n",
    "    \"\"\"\n",
    "    Picks the closest snapshot version <= catalog_date.\n",
    "    Uses: any trusted snapshot dict (Colleges, Degrees, etc).\n",
    "    Returns: List for Colleges or dict for Degrees.\n",
    "    \"\"\"\n",
    "    versions = sorted(snapshot_dict.keys())\n",
    "    chosen = None\n",
    "    for version in versions:\n",
    "        if version <= date_str:\n",
    "            chosen = version\n",
    "    if not chosen:\n",
    "        raise ValueError(f\"[FAIL] No snapshot version found for {date_str}\")\n",
    "    return snapshot_dict[chosen]\n",
    "\n",
    "print(\"[V10] College snapshots loaded and snapshot picker ready. ✅\")\n",
    "\n",
    "[V10] College snapshots loaded and snapshot picker ready. ✅\n",
    "\n",
    "\"\"\"\n",
    "================================================================\n",
    "Scraper_V10 — Locate First Academic Program Section\n",
    "----------------------------------------------------------------\n",
    "Utility:\n",
    "  - get_program_section_start(lines, valid_colleges)\n",
    "  - Finds first CCN table, walks up to enclosing College.\n",
    "  - Returns index to fence Degree parse.\n",
    "----------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "def get_program_section_start(lines: list, valid_colleges: list) -> int:\n",
    "    \"\"\"\n",
    "    Finds the line index where the first CCN table appears,\n",
    "    then walks upward to find the enclosing College name.\n",
    "    \"\"\"\n",
    "    first_ccn_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if ANCHORS[\"CCN_HEADER\"].search(line):\n",
    "            first_ccn_idx = i\n",
    "            break\n",
    "\n",
    "    if first_ccn_idx is None:\n",
    "        raise ValueError(\"[FAIL] No CCN table header found.\")\n",
    "\n",
    "    for j in range(first_ccn_idx, -1, -1):\n",
    "        if lines[j].strip() in valid_colleges:\n",
    "            return j\n",
    "\n",
    "    raise ValueError(\"[FAIL] No valid College header found above first CCN table.\")\n",
    "\n",
    "print(\"[V10] Program section locator loaded. ✅\")\n",
    "\n",
    "[V10] Program section locator loaded. ✅\n",
    "\n",
    "\"\"\"\n",
    "================================================================\n",
    "Scraper_V10 — Course Row Pattern Matcher\n",
    "----------------------------------------------------------------\n",
    "Utility:\n",
    "  - match_course_row(row)\n",
    "  - Checks row against CCN_FULL, CODE_ONLY, FALLBACK.\n",
    "  - Returns { matched_pattern, groups }\n",
    "  - If no match → return None.\n",
    "----------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "def match_course_row(row: str) -> dict:\n",
    "    \"\"\"\n",
    "    Attempts to classify the given course row.\n",
    "    Order enforced: CCN_FULL → CODE_ONLY → FALLBACK.\n",
    "    \"\"\"\n",
    "    for pattern_name, pattern in COURSE_PATTERNS.items():\n",
    "        match = pattern.match(row)\n",
    "        if match:\n",
    "            return {\n",
    "                \"matched_pattern\": pattern_name,\n",
    "                \"groups\": match.groups()\n",
    "            }\n",
    "    return None\n",
    "\n",
    "print(\"[V10] Course row matcher loaded. ✅\")\n",
    "\n",
    "[V10] Course row matcher loaded. ✅\n",
    "\n",
    "\"\"\"\n",
    "================================================================\n",
    "Scraper_V10 — Quick Test: Parse Single Catalog\n",
    "----------------------------------------------------------------\n",
    "Example:\n",
    "  - Loads one .txt from plumber_parsed.\n",
    "  - Uses College snapshot.\n",
    "  - Fences first CCN block.\n",
    "  - Runs row matcher.\n",
    "----------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "# Example .txt to test\n",
    "TEST_FILE = \"../WGU_catalog/catalogs/plumber_parsed/catalog_2017_01.txt\"\n",
    "\n",
    "# Extract date\n",
    "parts = os.path.basename(TEST_FILE).replace(\".txt\", \"\").split(\"_\")\n",
    "CATALOG_DATE = f\"{parts[1]}-{parts[2]}\"\n",
    "print(f\"📅 Testing Catalog Date: {CATALOG_DATE}\")\n",
    "\n",
    "valid_colleges = pick_snapshot(CATALOG_DATE, college_snapshots)\n",
    "print(f\"✅ Colleges: {valid_colleges}\")\n",
    "\n",
    "with open(TEST_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = [l.strip() for l in f]\n",
    "\n",
    "start_idx = get_program_section_start(lines, valid_colleges)\n",
    "print(f\"Program section starts at line {start_idx}: {lines[start_idx]}\")\n",
    "\n",
    "# Scan lines inside the fence for demonstration\n",
    "lines_to_scan = lines[start_idx:]\n",
    "\n",
    "candidate_rows = []\n",
    "for i, line in enumerate(lines_to_scan):\n",
    "    if ANCHORS[\"CCN_HEADER\"].search(line):\n",
    "        # Next lines assumed candidate course rows\n",
    "        for j in range(i+1, min(i+20, len(lines_to_scan))):  # demo only\n",
    "            row = lines_to_scan[j].strip()\n",
    "            if row:\n",
    "                candidate_rows.append((j, row))\n",
    "\n",
    "print(f\"Found {len(candidate_rows)} candidate rows.\")\n",
    "print(\"\\nSample matches:\\n\")\n",
    "\n",
    "for line_idx, row in candidate_rows[:10]:\n",
    "    result = match_course_row(row)\n",
    "    if result:\n",
    "        print(f\"  Line {line_idx}: {row}  → {result['matched_pattern']}\")\n",
    "    else:\n",
    "        print(f\"  Line {line_idx}: {row}  → No Match\")\n",
    "\n",
    "📅 Testing Catalog Date: 2017-01\n",
    "✅ Colleges: ['College of Business', 'College of Health Professions', 'College of Information Technology', 'Teachers College']\n",
    "Program section starts at line 9: College of Health Professions\n",
    "Found 1729 candidate rows.\n",
    "\n",
    "Sample matches:\n",
    "\n",
    "  Line 2197: BUS 2100 C711 Introduction to Business 3 1  → CCN_FULL\n",
    "  Line 2198: ENGL 1010 C455 English Composition I 3 1  → CCN_FULL\n",
    "  Line 2199: GEOG 1311 C255 Introduction to Geography 3 1  → CCN_FULL\n",
    "  Line 2200: BUS 2301 C483 Principles of Management 4 1  → CCN_FULL\n",
    "  Line 2201: ENGL 1020 C456 English Composition II 3 2  → CCN_FULL\n",
    "  Line 2202: MGMT 3000 C715 Organizational Behavior 3 2  → CCN_FULL\n",
    "  Line 2203: MATH 1010 C463 Intermediate Algebra 3 2  → CCN_FULL\n",
    "  Line 2204: LAW 3000 C713 Business Law 3 2  → CCN_FULL\n",
    "  Line 2205: MATH 1015 C278 College Algebra 4 3  → CCN_FULL\n",
    "  Line 2206: SCIE 1010 C451 Integrated Natural Science 4 3  → CCN_FULL\n",
    "\n",
    "\"\"\"\n",
    "================================================================\n",
    "Scraper_V10 — Build Verified Degree Fences (V10 Locked)\n",
    "----------------------------------------------------------------\n",
    "Purpose:\n",
    "  - For each parsed catalog:\n",
    "      - Use trusted { College → Degree } from program_names_v10.json.\n",
    "      - Find Degree name in .txt.\n",
    "      - Walk FORWARD to pin first CCN_HEADER for that Degree.\n",
    "      - Fence stops at:\n",
    "          - Next Degree name,\n",
    "          - Next College name,\n",
    "          - Known footer anchor,\n",
    "          - Or EOF.\n",
    "  - Logs any Degree missing CCN block.\n",
    "  - Produces: sections_index_v10.json → single truth for Degree fences.\n",
    "================================================================\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "# === Anchors ===\n",
    "ANCHOR_CCN_HEADER = re.compile(r\"CCN.*Course Number\", re.IGNORECASE)\n",
    "ANCHOR_COLLEGE = re.compile(r\"College of \", re.IGNORECASE)\n",
    "ANCHOR_TOTAL_CUS = re.compile(r\"Total CUs\", re.IGNORECASE)\n",
    "ANCHOR_COPYRIGHT = re.compile(r\"©\")\n",
    "\n",
    "# === Directories ===\n",
    "TEXT_DIR = \"../WGU_catalog/catalogs/plumber_parsed/\"\n",
    "PROGRAM_NAMES_DIR = \"../WGU_catalog/outputs/program_names/\"\n",
    "OUTPUT_SECTIONS_INDEX = \"../WGU_catalog/helpers/sections_index_v10.json\"\n",
    "\n",
    "sections_index = {}\n",
    "\n",
    "catalog_files = sorted([f for f in os.listdir(TEXT_DIR) if f.endswith(\".txt\")])\n",
    "\n",
    "for FILE_NAME in catalog_files:\n",
    "    FILE_PATH = os.path.join(TEXT_DIR, FILE_NAME)\n",
    "    DATE_PART = FILE_NAME.replace(\".txt\", \"\").split(\"_\")[1:]\n",
    "    CATALOG_DATE = f\"{DATE_PART[0]}-{DATE_PART[1]}\"\n",
    "    print(f\"\\n📅 Processing: {CATALOG_DATE}\")\n",
    "\n",
    "    # === Load Degree names ===\n",
    "    degree_names_path = os.path.join(PROGRAM_NAMES_DIR, f\"{DATE_PART[0]}_{DATE_PART[1]}_program_names_v10.json\")\n",
    "    if not os.path.exists(degree_names_path):\n",
    "        print(f\"❌ No Degree names JSON for {CATALOG_DATE} — skipping.\")\n",
    "        continue\n",
    "\n",
    "    with open(degree_names_path, 'r') as f:\n",
    "        degree_names = json.load(f)\n",
    "\n",
    "    # === Load lines ===\n",
    "    with open(FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        lines = [l.strip() for l in f]\n",
    "\n",
    "    sections_index.setdefault(CATALOG_DATE, {})\n",
    "\n",
    "    for college, programs in degree_names.items():\n",
    "        sections_index[CATALOG_DATE].setdefault(college, {})\n",
    "\n",
    "        for degree_name in programs:\n",
    "            start_idx = None\n",
    "            stop_idx = len(lines)\n",
    "\n",
    "            # === 1. Find Degree heading ===\n",
    "            degree_heading_idx = None\n",
    "            for i, line in enumerate(lines):\n",
    "                if line == degree_name:\n",
    "                    degree_heading_idx = i\n",
    "                    break\n",
    "            if degree_heading_idx is None:\n",
    "                print(f\"⚠️  Degree name not found: {degree_name} in {catalog_date} ({college})\")\n",
    "                continue\n",
    "\n",
    "            # === 2. Forward scan to first CCN_HEADER ===\n",
    "            for j in range(degree_heading_idx, len(lines)):\n",
    "                if ANCHOR_CCN_HEADER.search(lines[j]):\n",
    "                    start_idx = j\n",
    "                    break\n",
    "            if start_idx is None:\n",
    "                print(f\"⚠️  No CCN table found for: {degree_name} in {catalog_date} ({college})\")\n",
    "                continue\n",
    "\n",
    "            # === 3. Find stop fence ===\n",
    "            for k in range(start_idx + 1, len(lines)):\n",
    "                next_line = lines[k].strip()\n",
    "                if next_line in programs and next_line != degree_name:\n",
    "                    stop_idx = k\n",
    "                    break\n",
    "                if ANCHOR_COLLEGE.search(next_line):\n",
    "                    stop_idx = k\n",
    "                    break\n",
    "                if ANCHOR_TOTAL_CUS.search(next_line) or ANCHOR_COPYRIGHT.search(next_line):\n",
    "                    stop_idx = k\n",
    "                    break\n",
    "\n",
    "            sections_index[CATALOG_DATE][college][degree_name] = [start_idx, stop_idx]\n",
    "            print(f\"✅ {degree_name}: [{start_idx}, {stop_idx}]\")\n",
    "\n",
    "# === Save final fences ===\n",
    "with open(OUTPUT_SECTIONS_INDEX, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sections_index, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ sections_index_v10.json saved: {OUTPUT_SECTIONS_INDEX}\")\n",
    "\n",
    "\"\"\"\n",
    "================================================================\n",
    "Scraper_V10 — Build Verified Degree Snapshots (V10 Locked)\n",
    "----------------------------------------------------------------\n",
    "Purpose:\n",
    "  - Consolidate all raw parsed program names per catalog.\n",
    "  - Resolve Degree name duplicates using trusted master map.\n",
    "  - Enforce unique placement for Certificates:\n",
    "      • Embedded in Colleges.\n",
    "      • Or fenced separately as trailing Certificates.\n",
    "  - Strictly match canonical College order from snapshot.\n",
    "  - Output:\n",
    "      • degree_snapshots_v10_seed.json → single truth for Degree lists.\n",
    "  - Fails if:\n",
    "      • Any Certificate appears in both embedded and trailing.\n",
    "      • Any expected College is missing from parsed output.\n",
    "================================================================\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# === Paths ===\n",
    "OUTPUT_DIR = Path(\"../WGU_catalog/outputs/program_names/\")\n",
    "HELPERS_DIR = Path(\"../WGU_catalog/helpers/\")\n",
    "\n",
    "COLLEGE_SNAPSHOTS_FILE = HELPERS_DIR / \"college_snapshots.json\"\n",
    "DEGREE_DUPLICATES_FILE = HELPERS_DIR / \"degree_duplicates_master_v10.json\"\n",
    "DEGREE_SNAPSHOTS_OUT_FILE = HELPERS_DIR / \"degree_snapshots_v10_seed.json\"\n",
    "\n",
    "# === Load trusted references ===\n",
    "with open(COLLEGE_SNAPSHOTS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    college_snapshots = json.load(f)\n",
    "\n",
    "with open(DEGREE_DUPLICATES_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    degree_duplicates = json.load(f)\n",
    "\n",
    "degree_snapshots = {}\n",
    "\n",
    "# === Determine snapshot versions ===\n",
    "snapshot_versions = sorted(college_snapshots.keys())\n",
    "\n",
    "def pick_snapshot(catalog_date):\n",
    "    chosen = None\n",
    "    for version in snapshot_versions:\n",
    "        if version <= catalog_date:\n",
    "            chosen = version\n",
    "    if not chosen:\n",
    "        raise ValueError(f\"[FAIL] No valid College snapshot found for {catalog_date}\")\n",
    "    return chosen\n",
    "\n",
    "# === Process each parsed program_names_v10.json ===\n",
    "for program_file in sorted(OUTPUT_DIR.glob(\"*_program_names_v10.json\")):\n",
    "    catalog_date = program_file.stem.split(\"_program_names_v10\")[0].replace(\"_\", \"-\")\n",
    "\n",
    "    with open(program_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        program_names = json.load(f)\n",
    "\n",
    "    snapshot_version = pick_snapshot(catalog_date)\n",
    "    canonical_order = college_snapshots[snapshot_version]\n",
    "\n",
    "    snapshot_unsorted = {}\n",
    "    embedded_certificates = set()\n",
    "    trailing_certificates = []\n",
    "\n",
    "    for college_name, degrees in program_names.items():\n",
    "        resolved_degrees = []\n",
    "        for degree in degrees:\n",
    "            degree = degree.strip()\n",
    "            if degree in degree_duplicates:\n",
    "                degree = degree_duplicates[degree]\n",
    "            resolved_degrees.append(degree)\n",
    "\n",
    "        if college_name == \"Certificates - Standard Paths\":\n",
    "            trailing_certificates.extend(resolved_degrees)\n",
    "        else:\n",
    "            unique_sorted = sorted(set(resolved_degrees))\n",
    "            snapshot_unsorted[college_name] = unique_sorted\n",
    "\n",
    "            for degree in unique_sorted:\n",
    "                if \"Certificate\" in degree:\n",
    "                    embedded_certificates.add(degree)\n",
    "\n",
    "    if trailing_certificates:\n",
    "        trailing_certificates = sorted(set(trailing_certificates))\n",
    "        overlap = embedded_certificates.intersection(trailing_certificates)\n",
    "        if overlap:\n",
    "            raise ValueError(\n",
    "                f\"[FAIL] Overlapping Certificates found in both embedded Colleges \"\n",
    "                f\"and trailing Certificates - Standard Paths for {catalog_date}: {overlap}\"\n",
    "            )\n",
    "        snapshot_unsorted[\"Certificates - Standard Paths\"] = trailing_certificates\n",
    "\n",
    "    # === Enforce canonical College order ===\n",
    "    snapshot_ordered = {}\n",
    "    for college in canonical_order:\n",
    "        if college in snapshot_unsorted:\n",
    "            snapshot_ordered[college] = snapshot_unsorted[college]\n",
    "        else:\n",
    "            if college == \"Certificates - Standard Paths\":\n",
    "                continue  # Optional trailing block\n",
    "            raise ValueError(\n",
    "                f\"[FAIL] Expected College '{college}' not found in parsed output for {catalog_date} \"\n",
    "                f\"(using snapshot version {snapshot_version})\"\n",
    "            )\n",
    "\n",
    "    degree_snapshots[catalog_date] = snapshot_ordered\n",
    "\n",
    "# === Save final Degree snapshot ===\n",
    "with open(DEGREE_SNAPSHOTS_OUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(degree_snapshots, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"[PASS] degree_snapshots_v10_seed.json built successfully → {DEGREE_SNAPSHOTS_OUT_FILE}\")\n",
    "\n",
    "[PASS] degree_snapshots_v10_seed.json built successfully → ../WGU_catalog/helpers/degree_snapshots_v10_seed.json\n",
    "\n",
    "\n",
    "# === Save snapshot ===\n",
    "with open(\"course_index_v10.json\", \"w\") as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(\"\\n📁 course_index_v10.json written. Review for any drift or orphans.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0642a20-0ba1-40ab-9bb7-6da58564c8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a07edc6a-4c9d-44a1-b141-c8d74af85209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchors & Patterns loaded.\n"
     ]
    }
   ],
   "source": [
    "# anchors_and_patterns.py\n",
    "\n",
    "import re\n",
    "\n",
    "# Anchors\n",
    "ANCHOR_CCN_HEADER = re.compile(r\"CCN.*Course Number\", re.IGNORECASE)\n",
    "ANCHOR_COURSE_CODE = re.compile(r\"^[A-Z]{2,4}\\s+\\d{4}\")\n",
    "ANCHOR_COURSES_SECTION_BREAK = re.compile(r\"^Courses\", re.IGNORECASE)\n",
    "ANCHOR_PROGRAM_OUTCOMES = re.compile(r\"^Program Outcomes$\", re.IGNORECASE)\n",
    "ANCHOR_SCHOOL_OF = re.compile(r\"^School of \", re.IGNORECASE)\n",
    "ANCHOR_FOOTER_COPYRIGHT = re.compile(r\"©\", re.IGNORECASE)\n",
    "ANCHOR_FOOTER_TOTAL_CUS = re.compile(r\"Total CUs\", re.IGNORECASE)\n",
    "\n",
    "# Filters\n",
    "PROGRAM_TITLE_EXCLUDE_PATTERNS = re.compile(r\"^(Steps|[0-9]|[•\\-])\")\n",
    "\n",
    "# Course row patterns\n",
    "PATTERN_CCN_FULL = re.compile(\n",
    "    r'^([A-Z]{2,5})\\s+(\\d{1,4})\\s+([A-Z0-9]{2,5})\\s+(.+?)\\s+(\\d+)\\s+(\\d+)$'\n",
    ")\n",
    "PATTERN_CODE_ONLY = re.compile(\n",
    "    r'^([A-Z0-9]{1,6})\\s+(.+?)\\s+(\\d+)\\s+(\\d+)$'\n",
    ")\n",
    "PATTERN_FALLBACK = re.compile(\n",
    "    r'^(.+?)\\s+(\\d+)\\s+(\\d+)$'\n",
    ")\n",
    "\n",
    "# Registered\n",
    "ANCHORS = {\n",
    "    \"CCN_HEADER\": ANCHOR_CCN_HEADER,\n",
    "    \"COURSE_CODE\": ANCHOR_COURSE_CODE,\n",
    "    \"COURSES_SECTION_BREAK\": ANCHOR_COURSES_SECTION_BREAK,\n",
    "    \"PROGRAM_OUTCOMES\": ANCHOR_PROGRAM_OUTCOMES,\n",
    "    \"SCHOOL_OF\": ANCHOR_SCHOOL_OF,\n",
    "    \"FOOTER_COPYRIGHT\": ANCHOR_FOOTER_COPYRIGHT,\n",
    "    \"FOOTER_TOTAL_CUS\": ANCHOR_FOOTER_TOTAL_CUS\n",
    "}\n",
    "\n",
    "FILTERS = {\n",
    "    \"PROGRAM_TITLE_EXCLUDE_PATTERNS\": PROGRAM_TITLE_EXCLUDE_PATTERNS\n",
    "}\n",
    "\n",
    "COURSE_PATTERNS = {\n",
    "    \"CCN_FULL\": PATTERN_CCN_FULL,\n",
    "    \"CODE_ONLY\": PATTERN_CODE_ONLY,\n",
    "    \"FALLBACK\": PATTERN_FALLBACK\n",
    "}\n",
    "\n",
    "print(\"Anchors & Patterns loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d78bf7d-d889-48c3-9487-9cb335cc93f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "College snapshots loaded.\n"
     ]
    }
   ],
   "source": [
    "# scraper_v10_snapshots.py — Load College Snapshots\n",
    "\n",
    "import json\n",
    "\n",
    "SNAPSHOT_COLLEGES_PATH = \"../WGU_catalog/helpers/college_snapshots.json\"\n",
    "\n",
    "with open(SNAPSHOT_COLLEGES_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    college_snapshots = json.load(f)\n",
    "\n",
    "def pick_snapshot(date_str: str, snapshot_dict: dict) -> list:\n",
    "    versions = sorted(snapshot_dict.keys())\n",
    "    chosen = None\n",
    "    for version in versions:\n",
    "        if version <= date_str:\n",
    "            chosen = version\n",
    "    if not chosen:\n",
    "        raise ValueError(f\"No snapshot version found for {date_str}\")\n",
    "    return snapshot_dict[chosen]\n",
    "\n",
    "print(\"College snapshots loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db0ca310-9f68-46ef-8e85-0104298aa342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program section locator loaded.\n"
     ]
    }
   ],
   "source": [
    "# scraper_v10_program_section.py — Locate Program Section\n",
    "\n",
    "def get_program_section_start(lines: list, valid_colleges: list) -> int:\n",
    "    first_ccn_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if ANCHORS[\"CCN_HEADER\"].search(line):\n",
    "            first_ccn_idx = i\n",
    "            break\n",
    "\n",
    "    if first_ccn_idx is None:\n",
    "        raise ValueError(\"No CCN table header found.\")\n",
    "\n",
    "    for j in range(first_ccn_idx, -1, -1):\n",
    "        if lines[j].strip() in valid_colleges:\n",
    "            return j\n",
    "\n",
    "    raise ValueError(\"No valid College header found above first CCN table.\")\n",
    "\n",
    "print(\"Program section locator loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4fcde311-89a6-43c9-91ce-6766f64ae6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUS 2100 C711 Business Management 3 1  →  CCN_FULL\n",
      "C711 Business Management 3 1  →  CODE_ONLY\n",
      "Business Management 3 1  →  FALLBACK\n",
      "This is clearly junk  →  No Match\n"
     ]
    }
   ],
   "source": [
    "# match_course_row.py\n",
    "\n",
    "def match_course_row(row: str) -> dict:\n",
    "    \"\"\"\n",
    "    Try to match row: CCN_FULL → CODE_ONLY → FALLBACK.\n",
    "    Return { pattern name, groups } or None.\n",
    "    \"\"\"\n",
    "    for pattern_name, pattern in COURSE_PATTERNS.items():\n",
    "        match = pattern.match(row)\n",
    "        if match:\n",
    "            return {\n",
    "                \"matched_pattern\": pattern_name,\n",
    "                \"groups\": match.groups()\n",
    "            }\n",
    "    return None\n",
    "\n",
    "\n",
    "# --- Example test ---\n",
    "sample_rows = [\n",
    "    \"BUS 2100 C711 Business Management 3 1\",\n",
    "    \"C711 Business Management 3 1\",\n",
    "    \"Business Management 3 1\",\n",
    "    \"This is clearly junk\"\n",
    "]\n",
    "\n",
    "for row in sample_rows:\n",
    "    result = match_course_row(row)\n",
    "    if result:\n",
    "        print(f\"{row}  →  {result['matched_pattern']}\")\n",
    "    else:\n",
    "        print(f\"{row}  →  No Match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4fcf095f-d54e-4f83-b40b-0f1e1f349f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample fence → 2017-01 | College of Health Professions | Master of Business Administration 66 : [39, 40]\n"
     ]
    }
   ],
   "source": [
    "# build_degree_fences.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "TEXT_DIR = \"../WGU_catalog/catalogs/plumber_parsed/\"\n",
    "PROGRAM_NAMES_DIR = \"../WGU_catalog/outputs/program_names/\"\n",
    "OUTPUT_SECTIONS_INDEX = \"../WGU_catalog/helpers/sections_index_v10.json\"\n",
    "\n",
    "ANCHOR_CCN_HEADER = ANCHORS[\"CCN_HEADER\"]\n",
    "ANCHOR_FOOTER_COPYRIGHT = ANCHORS[\"FOOTER_COPYRIGHT\"]\n",
    "ANCHOR_FOOTER_TOTAL_CUS = ANCHORS[\"FOOTER_TOTAL_CUS\"]\n",
    "\n",
    "sections_index = {}\n",
    "\n",
    "catalog_files = sorted([f for f in os.listdir(TEXT_DIR) if f.endswith(\".txt\")])\n",
    "\n",
    "for FILE_NAME in catalog_files:\n",
    "    FILE_PATH = os.path.join(TEXT_DIR, FILE_NAME)\n",
    "    DATE_PART = FILE_NAME.replace(\".txt\", \"\").split(\"_\")[1:]\n",
    "    CATALOG_DATE = f\"{DATE_PART[0]}-{DATE_PART[1]}\"\n",
    "\n",
    "    degree_names_path = os.path.join(PROGRAM_NAMES_DIR, f\"{DATE_PART[0]}_{DATE_PART[1]}_program_names_v10.json\")\n",
    "    if not os.path.exists(degree_names_path):\n",
    "        continue\n",
    "\n",
    "    with open(degree_names_path, \"r\") as f:\n",
    "        degree_names = json.load(f)\n",
    "\n",
    "    with open(FILE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [l.strip() for l in f]\n",
    "\n",
    "    sections_index.setdefault(CATALOG_DATE, {})\n",
    "\n",
    "    for college, programs in degree_names.items():\n",
    "        sections_index[CATALOG_DATE].setdefault(college, {})\n",
    "\n",
    "        for degree_name in programs:\n",
    "            start_idx = None\n",
    "            stop_idx = len(lines)\n",
    "\n",
    "            for i, line in enumerate(lines):\n",
    "                if line == degree_name:\n",
    "                    start_idx = i\n",
    "                    break\n",
    "            if start_idx is None:\n",
    "                continue\n",
    "\n",
    "            for j in range(start_idx + 1, len(lines)):\n",
    "                next_line = lines[j].strip()\n",
    "                if next_line in programs and next_line != degree_name:\n",
    "                    stop_idx = j\n",
    "                    break\n",
    "                if any(next_line == c for c in degree_names.keys()):\n",
    "                    stop_idx = j\n",
    "                    break\n",
    "                if ANCHOR_FOOTER_COPYRIGHT.search(next_line) or ANCHOR_FOOTER_TOTAL_CUS.search(next_line):\n",
    "                    stop_idx = j\n",
    "                    break\n",
    "\n",
    "            sections_index[CATALOG_DATE][college][degree_name] = [start_idx, stop_idx]\n",
    "\n",
    "# Save\n",
    "with open(OUTPUT_SECTIONS_INDEX, \"w\") as f:\n",
    "    json.dump(sections_index, f, indent=2)\n",
    "\n",
    "# Show sample fence\n",
    "sample_date = sorted(sections_index.keys())[0]\n",
    "sample_college = list(sections_index[sample_date].keys())[0]\n",
    "sample_degree = list(sections_index[sample_date][sample_college].keys())[0]\n",
    "print(f\"Sample fence → {sample_date} | {sample_college} | {sample_degree} : {sections_index[sample_date][sample_college][sample_degree]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fcea162e-9c02-47b8-b871-e9f0a881f915",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing expected College: College of Business (2017-01)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     73\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     74\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing expected College: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollege\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcatalog_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     77\u001b[39m     degree_snapshots[catalog_date] = snapshot_ordered\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(DEGREE_SNAPSHOTS_OUT_FILE, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mValueError\u001b[39m: Missing expected College: College of Business (2017-01)"
     ]
    }
   ],
   "source": [
    "# build_degree_snapshots.py\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "OUTPUT_DIR = Path(\"../WGU_catalog/outputs/program_names/\")\n",
    "HELPERS_DIR = Path(\"../WGU_catalog/helpers/\")\n",
    "\n",
    "COLLEGE_SNAPSHOTS_FILE = HELPERS_DIR / \"college_snapshots.json\"\n",
    "DEGREE_DUPLICATES_FILE = HELPERS_DIR / \"degree_duplicates_master_v10.json\"\n",
    "DEGREE_SNAPSHOTS_OUT_FILE = HELPERS_DIR / \"degree_snapshots_v10_seed.json\"\n",
    "\n",
    "with open(COLLEGE_SNAPSHOTS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    college_snapshots = json.load(f)\n",
    "\n",
    "with open(DEGREE_DUPLICATES_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    degree_duplicates = json.load(f)\n",
    "\n",
    "degree_snapshots = {}\n",
    "\n",
    "snapshot_versions = sorted(college_snapshots.keys())\n",
    "\n",
    "def pick_snapshot(date):\n",
    "    chosen = None\n",
    "    for version in snapshot_versions:\n",
    "        if version <= date:\n",
    "            chosen = version\n",
    "    if not chosen:\n",
    "        raise ValueError(f\"No snapshot for {date}\")\n",
    "    return chosen\n",
    "\n",
    "for program_file in sorted(OUTPUT_DIR.glob(\"*_program_names_v10.json\")):\n",
    "    catalog_date = program_file.stem.split(\"_program_names_v10\")[0].replace(\"_\", \"-\")\n",
    "\n",
    "    with open(program_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        program_names = json.load(f)\n",
    "\n",
    "    snapshot_version = pick_snapshot(catalog_date)\n",
    "    canonical_order = college_snapshots[snapshot_version]\n",
    "\n",
    "    snapshot_unsorted = {}\n",
    "    embedded_certificates = set()\n",
    "    trailing_certificates = []\n",
    "\n",
    "    for college_name, degrees in program_names.items():\n",
    "        resolved = []\n",
    "        for degree in degrees:\n",
    "            degree = degree.strip()\n",
    "            if degree in degree_duplicates:\n",
    "                degree = degree_duplicates[degree]\n",
    "            resolved.append(degree)\n",
    "\n",
    "        if college_name == \"Certificates - Standard Paths\":\n",
    "            trailing_certificates.extend(resolved)\n",
    "        else:\n",
    "            snapshot_unsorted[college_name] = sorted(set(resolved))\n",
    "            for d in resolved:\n",
    "                if \"Certificate\" in d:\n",
    "                    embedded_certificates.add(d)\n",
    "\n",
    "    if trailing_certificates:\n",
    "        trailing_certificates = sorted(set(trailing_certificates))\n",
    "        overlap = embedded_certificates.intersection(trailing_certificates)\n",
    "        if overlap:\n",
    "            raise ValueError(f\"Overlap: {overlap}\")\n",
    "        snapshot_unsorted[\"Certificates - Standard Paths\"] = trailing_certificates\n",
    "\n",
    "    snapshot_ordered = {}\n",
    "    for college in canonical_order:\n",
    "        if college in snapshot_unsorted:\n",
    "            snapshot_ordered[college] = snapshot_unsorted[college]\n",
    "        elif college == \"Certificates - Standard Paths\":\n",
    "            continue\n",
    "        else:\n",
    "            raise ValueError(f\"Missing expected College: {college} ({catalog_date})\")\n",
    "\n",
    "    degree_snapshots[catalog_date] = snapshot_ordered\n",
    "\n",
    "with open(DEGREE_SNAPSHOTS_OUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(degree_snapshots, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "sample_date = sorted(degree_snapshots.keys())[0]\n",
    "print(f\"Sample snapshot → {sample_date}: {list(degree_snapshots[sample_date].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70c43902-a587-42ab-b5fe-6a8c033e7676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Raw Course Row Counts by Catalog:\n",
      "\n",
      "2017:\n",
      "  • 2017_01: 1330 rows\n",
      "  • 2017_03: 1324 rows\n",
      "  • 2017_05: 1324 rows\n",
      "  • 2017_07: 1368 rows\n",
      "  • 2017_08: 1366 rows\n",
      "  • 2017_09: 1369 rows\n",
      "  • 2017_10: 1370 rows\n",
      "  • 2017_11: 1375 rows\n",
      "  • 2017_12: 1375 rows\n",
      "\n",
      "2018:\n",
      "  • 2018_01: 1363 rows\n",
      "  • 2018_02: 1363 rows\n",
      "  • 2018_03: 1363 rows\n",
      "  • 2018_04: 1359 rows\n",
      "  • 2018_05: 1392 rows\n",
      "  • 2018_06: 1387 rows\n",
      "  • 2018_07: 1387 rows\n",
      "  • 2018_08: 1388 rows\n",
      "  • 2018_09: 1390 rows\n",
      "  • 2018_10: 1424 rows\n",
      "  • 2018_11: 1424 rows\n",
      "  • 2018_12: 1427 rows\n",
      "\n",
      "2019:\n",
      "  • 2019_01: 1426 rows\n",
      "  • 2019_02: 1426 rows\n",
      "  • 2019_03: 1426 rows\n",
      "  • 2019_04: 1428 rows\n",
      "  • 2019_05: 1428 rows\n",
      "  • 2019_06: 1428 rows\n",
      "  • 2019_07: 1428 rows\n",
      "  • 2019_08: 1424 rows\n",
      "  • 2019_09: 1458 rows\n",
      "  • 2019_10: 1458 rows\n",
      "  • 2019_11: 1458 rows\n",
      "  • 2019_12: 1458 rows\n",
      "\n",
      "2020:\n",
      "  • 2020_01: 1459 rows\n",
      "  • 2020_02: 1491 rows\n",
      "  • 2020_03: 1500 rows\n",
      "  • 2020_04: 1500 rows\n",
      "  • 2020_05: 1499 rows\n",
      "  • 2020_06: 1511 rows\n",
      "  • 2020_07: 1509 rows\n",
      "  • 2020_08: 1509 rows\n",
      "  • 2020_09: 1509 rows\n",
      "  • 2020_10: 1512 rows\n",
      "  • 2020_11: 1469 rows\n",
      "  • 2020_12: 1525 rows\n",
      "\n",
      "2021:\n",
      "  • 2021_01: 1525 rows\n",
      "  • 2021_02: 1525 rows\n",
      "  • 2021_03: 1542 rows\n",
      "  • 2021_04: 1542 rows\n",
      "  • 2021_05: 1542 rows\n",
      "  • 2021_06: 1542 rows\n",
      "  • 2021_07: 1542 rows\n",
      "  • 2021_08: 1542 rows\n",
      "  • 2021_09: 1468 rows\n",
      "  • 2021_10: 1469 rows\n",
      "  • 2021_11: 1469 rows\n",
      "  • 2021_12: 1469 rows\n",
      "\n",
      "2022:\n",
      "  • 2022_01: 1477 rows\n",
      "  • 2022_02: 1483 rows\n",
      "  • 2022_03: 1483 rows\n",
      "  • 2022_04: 1493 rows\n",
      "  • 2022_05: 1492 rows\n",
      "  • 2022_06: 1661 rows\n",
      "  • 2022_07: 1661 rows\n",
      "  • 2022_08: 1696 rows\n",
      "  • 2022_09: 1696 rows\n",
      "  • 2022_10: 1738 rows\n",
      "  • 2022_11: 1713 rows\n",
      "  • 2022_12: 1724 rows\n",
      "\n",
      "2023:\n",
      "  • 2023_01: 1775 rows\n",
      "  • 2023_02: 1775 rows\n",
      "  • 2023_03: 1775 rows\n",
      "  • 2023_04: 1810 rows\n",
      "  • 2023_05: 1827 rows\n",
      "  • 2023_06: 1827 rows\n",
      "  • 2023_07: 1827 rows\n",
      "  • 2023_08: 1839 rows\n",
      "  • 2023_09: 1843 rows\n",
      "  • 2023_10: 1843 rows\n",
      "  • 2023_11: 1843 rows\n",
      "  • 2023_12: 1881 rows\n",
      "\n",
      "2024:\n",
      "  • 2024_01: 1881 rows\n",
      "  • 2024_02: 1919 rows\n",
      "  • 2024_03: 1919 rows\n",
      "  • 2024_04: 1947 rows\n",
      "  • 2024_05: 1947 rows\n",
      "  • 2024_06: 1975 rows\n",
      "  • 2024_07: 2008 rows\n",
      "  • 2024_08: 1393 rows\n",
      "  • 2024_09: 1610 rows\n",
      "  • 2024_10: 1644 rows\n",
      "  • 2024_11: 1643 rows\n",
      "  • 2024_12: 1639 rows\n",
      "\n",
      "2025:\n",
      "  • 2025_01: 1634 rows\n",
      "  • 2025_02: 1778 rows\n",
      "  • 2025_03: 1677 rows\n",
      "  • 2025_04: 1680 rows\n",
      "  • 2025_05: 1680 rows\n",
      "  • 2025_06: 1691 rows\n"
     ]
    }
   ],
   "source": [
    "# pull_raw_course_rows.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "INPUT_DIR = \"../WGU_catalog/catalogs/plumber_parsed/\"\n",
    "OUTPUT_DIR = \"../WGU_catalog/outputs/raw_course_rows/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load college snapshots\n",
    "with open(\"../WGU_catalog/helpers/college_snapshots.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    snapshot_dict = json.load(f)\n",
    "\n",
    "ANCHOR_CCN_HEADER = ANCHORS[\"CCN_HEADER\"]\n",
    "ANCHOR_TOTAL_CUS = ANCHORS[\"FOOTER_TOTAL_CUS\"]\n",
    "ANCHOR_FOOTER_COPYRIGHT = ANCHORS[\"FOOTER_COPYRIGHT\"]\n",
    "\n",
    "def pick_snapshot(date_str: str, snapshot_dict: dict) -> list:\n",
    "    versions = sorted(snapshot_dict.keys())\n",
    "    chosen = None\n",
    "    for version in versions:\n",
    "        if version <= date_str:\n",
    "            chosen = version\n",
    "    if not chosen:\n",
    "        raise ValueError(f\"No snapshot version found for {date_str}\")\n",
    "    return snapshot_dict[chosen]\n",
    "\n",
    "# Track counts for final summary\n",
    "summary_by_year = {}\n",
    "\n",
    "for filename in sorted(os.listdir(INPUT_DIR)):\n",
    "    if not filename.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    FILE_PATH = os.path.join(INPUT_DIR, filename)\n",
    "    parts = filename.replace(\".txt\", \"\").split(\"_\")\n",
    "    DATE_PART = f\"{parts[1]}_{parts[2]}\"\n",
    "    CATALOG_DATE = f\"{parts[1]}-{parts[2]}\"\n",
    "    YEAR = parts[1]\n",
    "\n",
    "    valid_colleges = pick_snapshot(CATALOG_DATE, snapshot_dict)\n",
    "\n",
    "    with open(FILE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [l.strip() for l in f]\n",
    "\n",
    "    start_idx = get_program_section_start(lines, valid_colleges)\n",
    "    lines_to_scan = lines[start_idx:]\n",
    "\n",
    "    ccn_indices = [i for i, line in enumerate(lines_to_scan) if ANCHOR_CCN_HEADER.search(line)]\n",
    "\n",
    "    raw_course_rows = []\n",
    "    for idx, anchor_idx in enumerate(ccn_indices):\n",
    "        block_start = anchor_idx + 1\n",
    "        block_end = len(lines_to_scan)\n",
    "        if idx + 1 < len(ccn_indices):\n",
    "            block_end = ccn_indices[idx + 1]\n",
    "        for i in range(block_start, block_end):\n",
    "            line = lines_to_scan[i]\n",
    "            if ANCHOR_TOTAL_CUS.search(line) or ANCHOR_FOOTER_COPYRIGHT.search(line):\n",
    "                block_end = i\n",
    "                break\n",
    "        buffer = []\n",
    "        for i in range(block_start, block_end):\n",
    "            raw_line = lines_to_scan[i].strip()\n",
    "            if not raw_line:\n",
    "                continue\n",
    "            if match_course_row(raw_line) and buffer:\n",
    "                joined = \" \".join(buffer)\n",
    "                if match_course_row(joined):\n",
    "                    raw_course_rows.append(joined)\n",
    "                buffer = [raw_line]\n",
    "            else:\n",
    "                buffer.append(raw_line)\n",
    "        if buffer:\n",
    "            joined = \" \".join(buffer)\n",
    "            if match_course_row(joined):\n",
    "                raw_course_rows.append(joined)\n",
    "\n",
    "    # Add to yearly summary\n",
    "    summary_by_year.setdefault(YEAR, []).append((DATE_PART, len(raw_course_rows)))\n",
    "\n",
    "    # Write output\n",
    "    output_path = os.path.join(OUTPUT_DIR, f\"{DATE_PART}_raw_course_rows_v10.json\")\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(raw_course_rows, f, indent=2)\n",
    "\n",
    "# Final condensed summary\n",
    "print(\"\\n📊 Raw Course Row Counts by Catalog:\")\n",
    "for year in sorted(summary_by_year.keys()):\n",
    "    print(f\"\\n{year}:\")\n",
    "    for date_part, count in summary_by_year[year]:\n",
    "        print(f\"  • {date_part}: {count} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e48ede3-3080-4e39-a2bd-9cddb7c3a377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebcead1-18d4-4d08-b80e-2db34d9dc37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull_raw_course_rows_preview.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "INPUT_DIR = \"../WGU_catalog/catalogs/plumber_parsed/\"\n",
    "\n",
    "ANCHOR_CCN_HEADER = ANCHORS[\"CCN_HEADER\"]\n",
    "ANCHOR_TOTAL_CUS = ANCHORS[\"FOOTER_TOTAL_CUS\"]\n",
    "ANCHOR_FOOTER_COPYRIGHT = ANCHORS[\"FOOTER_COPYRIGHT\"]\n",
    "\n",
    "# Load college snapshots\n",
    "with open(\"../WGU_catalog/helpers/college_snapshots.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    snapshot_dict = json.load(f)\n",
    "\n",
    "def pick_snapshot(date_str: str, snapshot_dict: dict) -> list:\n",
    "    versions = sorted(snapshot_dict.keys())\n",
    "    chosen = None\n",
    "    for version in versions:\n",
    "        if version <= date_str:\n",
    "            chosen = version\n",
    "    if not chosen:\n",
    "        raise ValueError(f\"No snapshot version found for {date_str}\")\n",
    "    return snapshot_dict[chosen]\n",
    "\n",
    "def normalize_college(line):\n",
    "    return line.lower().replace(\" programs\", \"\").strip()\n",
    "\n",
    "def get_program_section_start(lines: list, valid_colleges: list) -> int:\n",
    "    first_ccn_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if ANCHOR_CCN_HEADER.search(line):\n",
    "            first_ccn_idx = i\n",
    "            break\n",
    "    if first_ccn_idx is None:\n",
    "        raise ValueError(\"No CCN table header found.\")\n",
    "    for j in range(first_ccn_idx, -1, -1):\n",
    "        line_norm = normalize_college(lines[j])\n",
    "        for college in valid_colleges:\n",
    "            if line_norm == college.lower():\n",
    "                return j\n",
    "    raise ValueError(\"No valid College header found above first CCN table.\")\n",
    "\n",
    "# Process each catalog\n",
    "for filename in sorted(os.listdir(INPUT_DIR)):\n",
    "    if not filename.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    FILE_PATH = os.path.join(INPUT_DIR, filename)\n",
    "    parts = filename.replace(\".txt\", \"\").split(\"_\")\n",
    "    DATE_PART = f\"{parts[1]}_{parts[2]}\"\n",
    "    CATALOG_DATE = f\"{parts[1]}-{parts[2]}\"\n",
    "\n",
    "    try:\n",
    "        valid_colleges = pick_snapshot(CATALOG_DATE, snapshot_dict)\n",
    "    except ValueError as e:\n",
    "        print(f\"‼️ {filename}: {e}\")\n",
    "        continue\n",
    "\n",
    "    with open(FILE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [l.strip() for l in f]\n",
    "\n",
    "    try:\n",
    "        start_idx = get_program_section_start(lines, valid_colleges)\n",
    "    except ValueError as e:\n",
    "        print(f\"‼️ {filename}: {e}\")\n",
    "        continue\n",
    "\n",
    "    lines_to_scan = lines[start_idx:]\n",
    "    ccn_indices = [i for i, line in enumerate(lines_to_scan) if ANCHOR_CCN_HEADER.search(line)]\n",
    "    \n",
    "    raw_course_rows = []\n",
    "    for idx, anchor_idx in enumerate(ccn_indices):\n",
    "        block_start = anchor_idx + 1\n",
    "        block_end = len(lines_to_scan)\n",
    "        if idx + 1 < len(ccn_indices):\n",
    "            block_end = ccn_indices[idx + 1]\n",
    "        for i in range(block_start, block_end):\n",
    "            line = lines_to_scan[i]\n",
    "            if ANCHOR_TOTAL_CUS.search(line) or ANCHOR_FOOTER_COPYRIGHT.search(line):\n",
    "                block_end = i\n",
    "                break\n",
    "        buffer = []\n",
    "        for i in range(block_start, block_end):\n",
    "            raw_line = lines_to_scan[i].strip()\n",
    "            if not raw_line:\n",
    "                continue\n",
    "            if match_course_row(raw_line) and buffer:\n",
    "                joined = \" \".join(buffer)\n",
    "                if match_course_row(joined):\n",
    "                    raw_course_rows.append(joined)\n",
    "                buffer = [raw_line]\n",
    "            else:\n",
    "                buffer.append(raw_line)\n",
    "        if buffer:\n",
    "            joined = \" \".join(buffer)\n",
    "            if match_course_row(joined):\n",
    "                raw_course_rows.append(joined)\n",
    "    print(f\"{filename} → raw rows: {len(raw_course_rows)}\")\n",
    "    for row in raw_course_rows[:5]:\n",
    "        print(f\"   • {row}\")\n",
    "    print(\"—\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451d0fe-1b4f-425d-9f84-85379514ddbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (WGU)",
   "language": "python",
   "name": "wgu-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
