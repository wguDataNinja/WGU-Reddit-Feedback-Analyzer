{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c80a3bc5-d02c-4d1e-8705-16cffc1f4972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchors & Patterns loaded.\n"
     ]
    }
   ],
   "source": [
    "# anchors_and_patterns.py\n",
    "\n",
    "import re\n",
    "\n",
    "# Anchors\n",
    "ANCHOR_CCN_HEADER = re.compile(r\"CCN.*Course Number\", re.IGNORECASE)\n",
    "ANCHOR_COURSE_CODE = re.compile(r\"^[A-Z]{2,4}\\s+\\d{4}\")\n",
    "ANCHOR_COURSES_SECTION_BREAK = re.compile(r\"^Courses\", re.IGNORECASE)\n",
    "ANCHOR_PROGRAM_OUTCOMES = re.compile(r\"^Program Outcomes$\", re.IGNORECASE)\n",
    "ANCHOR_SCHOOL_OF = re.compile(r\"^School of \", re.IGNORECASE)\n",
    "ANCHOR_FOOTER_COPYRIGHT = re.compile(r\"Â©\", re.IGNORECASE)\n",
    "ANCHOR_FOOTER_TOTAL_CUS = re.compile(r\"Total CUs\", re.IGNORECASE)\n",
    "\n",
    "# Filters\n",
    "PROGRAM_TITLE_EXCLUDE_PATTERNS = re.compile(r\"^(Steps|[0-9]|[â€¢\\-])\")\n",
    "\n",
    "# Course row patterns\n",
    "PATTERN_CCN_FULL = re.compile(\n",
    "    r'^([A-Z]{2,5})\\s+(\\d{1,4})\\s+([A-Z0-9]{2,5})\\s+(.+?)\\s+(\\d+)\\s+(\\d+)$'\n",
    ")\n",
    "PATTERN_CODE_ONLY = re.compile(\n",
    "    r'^([A-Z0-9]{1,6})\\s+(.+?)\\s+(\\d+)\\s+(\\d+)$'\n",
    ")\n",
    "PATTERN_FALLBACK = re.compile(\n",
    "    r'^(.+?)\\s+(\\d+)\\s+(\\d+)$'\n",
    ")\n",
    "\n",
    "# Registered\n",
    "ANCHORS = {\n",
    "    \"CCN_HEADER\": ANCHOR_CCN_HEADER,\n",
    "    \"COURSE_CODE\": ANCHOR_COURSE_CODE,\n",
    "    \"COURSES_SECTION_BREAK\": ANCHOR_COURSES_SECTION_BREAK,\n",
    "    \"PROGRAM_OUTCOMES\": ANCHOR_PROGRAM_OUTCOMES,\n",
    "    \"SCHOOL_OF\": ANCHOR_SCHOOL_OF,\n",
    "    \"FOOTER_COPYRIGHT\": ANCHOR_FOOTER_COPYRIGHT,\n",
    "    \"FOOTER_TOTAL_CUS\": ANCHOR_FOOTER_TOTAL_CUS\n",
    "}\n",
    "\n",
    "FILTERS = {\n",
    "    \"PROGRAM_TITLE_EXCLUDE_PATTERNS\": PROGRAM_TITLE_EXCLUDE_PATTERNS\n",
    "}\n",
    "\n",
    "COURSE_PATTERNS = {\n",
    "    \"CCN_FULL\": PATTERN_CCN_FULL,\n",
    "    \"CODE_ONLY\": PATTERN_CODE_ONLY,\n",
    "    \"FALLBACK\": PATTERN_FALLBACK\n",
    "}\n",
    "\n",
    "print(\"Anchors & Patterns loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "27e63d6a-f548-4f38-9cf2-ed2a3127b368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V10] College snapshots loaded and snapshot picker ready. âœ…\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================\n",
    "Scraper_V10 â€” Load College Snapshots (Canonical Order)\n",
    "----------------------------------------------------------------\n",
    "Loads:\n",
    "  - college_snapshots.json â†’ trusted order of Colleges per catalog date.\n",
    "Utility:\n",
    "  - pick_snapshot(catalog_date) â†’ picks snapshot version.\n",
    "Fails if:\n",
    "  - No snapshot version found <= catalog date.\n",
    "----------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "# === Path to trusted College snapshot ===\n",
    "SNAPSHOT_COLLEGES_PATH = \"../WGU_catalog/helpers/college_snapshots.json\"\n",
    "\n",
    "with open(SNAPSHOT_COLLEGES_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    college_snapshots = json.load(f)\n",
    "\n",
    "def pick_snapshot(date_str: str, snapshot_dict: dict) -> list:\n",
    "    \"\"\"\n",
    "    Picks the closest snapshot version <= catalog_date.\n",
    "    Uses: any trusted snapshot dict (Colleges, Degrees, etc).\n",
    "    Returns: List for Colleges or dict for Degrees.\n",
    "    \"\"\"\n",
    "    versions = sorted(snapshot_dict.keys())\n",
    "    chosen = None\n",
    "    for version in versions:\n",
    "        if version <= date_str:\n",
    "            chosen = version\n",
    "    if not chosen:\n",
    "        raise ValueError(f\"[FAIL] No snapshot version found for {date_str}\")\n",
    "    return snapshot_dict[chosen]\n",
    "\n",
    "print(\"[V10] College snapshots loaded and snapshot picker ready. âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "5973e2aa-6a12-4abc-bf6e-d632cb3c1b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V10] Program section locator loaded. âœ…\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================\n",
    "Scraper_V10 â€” Locate First Academic Program Section\n",
    "----------------------------------------------------------------\n",
    "Utility:\n",
    "  - get_program_section_start(lines, valid_colleges)\n",
    "  - Finds first CCN table, walks up to enclosing College.\n",
    "  - Returns index to fence Degree parse.\n",
    "----------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "def get_program_section_start(lines: list, valid_colleges: list) -> int:\n",
    "    \"\"\"\n",
    "    Finds the line index where the first CCN table appears,\n",
    "    then walks upward to find the enclosing College name.\n",
    "    \"\"\"\n",
    "    first_ccn_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if ANCHORS[\"CCN_HEADER\"].search(line):\n",
    "            first_ccn_idx = i\n",
    "            break\n",
    "\n",
    "    if first_ccn_idx is None:\n",
    "        raise ValueError(\"[FAIL] No CCN table header found.\")\n",
    "\n",
    "    for j in range(first_ccn_idx, -1, -1):\n",
    "        if lines[j].strip() in valid_colleges:\n",
    "            return j\n",
    "\n",
    "    raise ValueError(\"[FAIL] No valid College header found above first CCN table.\")\n",
    "\n",
    "print(\"[V10] Program section locator loaded. âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a62bcae6-44af-4c12-98f2-1b22b7f9e70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V10] Course row matcher loaded. âœ…\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================\n",
    "Scraper_V10 â€” Course Row Pattern Matcher\n",
    "----------------------------------------------------------------\n",
    "Utility:\n",
    "  - match_course_row(row)\n",
    "  - Checks row against CCN_FULL, CODE_ONLY, FALLBACK.\n",
    "  - Returns { matched_pattern, groups }\n",
    "  - If no match â†’ return None.\n",
    "----------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "def match_course_row(row: str) -> dict:\n",
    "    \"\"\"\n",
    "    Attempts to classify the given course row.\n",
    "    Order enforced: CCN_FULL â†’ CODE_ONLY â†’ FALLBACK.\n",
    "    \"\"\"\n",
    "    for pattern_name, pattern in COURSE_PATTERNS.items():\n",
    "        match = pattern.match(row)\n",
    "        if match:\n",
    "            return {\n",
    "                \"matched_pattern\": pattern_name,\n",
    "                \"groups\": match.groups()\n",
    "            }\n",
    "    return None\n",
    "\n",
    "print(\"[V10] Course row matcher loaded. âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b48c0fc9-4b8e-42a3-8412-e5886fc53697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“… Testing Catalog Date: 2017-01\n",
      "âœ… Colleges: ['College of Business', 'College of Health Professions', 'College of Information Technology', 'Teachers College']\n",
      "Program section starts at line 9: College of Health Professions\n",
      "Found 1729 candidate rows.\n",
      "\n",
      "Sample matches:\n",
      "\n",
      "  Line 2197: BUS 2100 C711 Introduction to Business 3 1  â†’ CCN_FULL\n",
      "  Line 2198: ENGL 1010 C455 English Composition I 3 1  â†’ CCN_FULL\n",
      "  Line 2199: GEOG 1311 C255 Introduction to Geography 3 1  â†’ CCN_FULL\n",
      "  Line 2200: BUS 2301 C483 Principles of Management 4 1  â†’ CCN_FULL\n",
      "  Line 2201: ENGL 1020 C456 English Composition II 3 2  â†’ CCN_FULL\n",
      "  Line 2202: MGMT 3000 C715 Organizational Behavior 3 2  â†’ CCN_FULL\n",
      "  Line 2203: MATH 1010 C463 Intermediate Algebra 3 2  â†’ CCN_FULL\n",
      "  Line 2204: LAW 3000 C713 Business Law 3 2  â†’ CCN_FULL\n",
      "  Line 2205: MATH 1015 C278 College Algebra 4 3  â†’ CCN_FULL\n",
      "  Line 2206: SCIE 1010 C451 Integrated Natural Science 4 3  â†’ CCN_FULL\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================\n",
    "Scraper_V10 â€” Quick Test: Parse Single Catalog\n",
    "----------------------------------------------------------------\n",
    "Example:\n",
    "  - Loads one .txt from plumber_parsed.\n",
    "  - Uses College snapshot.\n",
    "  - Fences first CCN block.\n",
    "  - Runs row matcher.\n",
    "----------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "# Example .txt to test\n",
    "TEST_FILE = \"../WGU_catalog/catalogs/plumber_parsed/catalog_2017_01.txt\"\n",
    "\n",
    "# Extract date\n",
    "parts = os.path.basename(TEST_FILE).replace(\".txt\", \"\").split(\"_\")\n",
    "CATALOG_DATE = f\"{parts[1]}-{parts[2]}\"\n",
    "print(f\"ðŸ“… Testing Catalog Date: {CATALOG_DATE}\")\n",
    "\n",
    "valid_colleges = pick_snapshot(CATALOG_DATE, college_snapshots)\n",
    "print(f\"âœ… Colleges: {valid_colleges}\")\n",
    "\n",
    "with open(TEST_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = [l.strip() for l in f]\n",
    "\n",
    "start_idx = get_program_section_start(lines, valid_colleges)\n",
    "print(f\"Program section starts at line {start_idx}: {lines[start_idx]}\")\n",
    "\n",
    "# Scan lines inside the fence for demonstration\n",
    "lines_to_scan = lines[start_idx:]\n",
    "\n",
    "candidate_rows = []\n",
    "for i, line in enumerate(lines_to_scan):\n",
    "    if ANCHORS[\"CCN_HEADER\"].search(line):\n",
    "        # Next lines assumed candidate course rows\n",
    "        for j in range(i+1, min(i+20, len(lines_to_scan))):  # demo only\n",
    "            row = lines_to_scan[j].strip()\n",
    "            if row:\n",
    "                candidate_rows.append((j, row))\n",
    "\n",
    "print(f\"Found {len(candidate_rows)} candidate rows.\")\n",
    "print(\"\\nSample matches:\\n\")\n",
    "\n",
    "for line_idx, row in candidate_rows[:10]:\n",
    "    result = match_course_row(row)\n",
    "    if result:\n",
    "        print(f\"  Line {line_idx}: {row}  â†’ {result['matched_pattern']}\")\n",
    "    else:\n",
    "        print(f\"  Line {line_idx}: {row}  â†’ No Match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "3d78c535-5d8a-48be-975c-2725ac654325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“… Processing: 2017-01\n",
      "âœ… Master of Business Administration 66: [2205, 2239]\n",
      "âœ… MBA Information Technology Management 67: [2205, 2239]\n",
      "âœ… MBA Healthcare Management 68: [2205, 2239]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Elementary Education (K-8) 121: [2205, 2239]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Mathematics (5-9) 122: [2205, 2239]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Mathematics (5-12) 123: [2205, 2239]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Science (5-9) 124: [2205, 2239]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Science (5-12) 125: [2205, 2239]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Social Science (5-12) 126: [2205, 2239]\n",
      "âœ… Endorsement Preparation Program, Educational Leadership 148: [2205, 2239]\n",
      "âœ… Endorsement Preparation Program, English Language Learning (PreK-12) 149: [2205, 2239]\n",
      "âœ… MBA, Harvard Ph.D., University of Arizona: [2205, 2239]\n",
      "âœ… MBA, Western Governors University Ph.D., Brigham Young University: [2205, 2239]\n",
      "âœ… postsecondary school required under 34 C.F.R. 600.9 to be legally authorized by the State of Utah.: [2205, 2239]\n",
      "âœ… posting of course results by the last day of the term.: [2205, 2239]\n",
      "âœ… Bachelor of Science, Business Management: [2205, 2239]\n",
      "\n",
      "ðŸ“… Processing: 2017-03\n",
      "âœ… Master of Business Administration 67: [2277, 2311]\n",
      "âœ… MBA Information Technology Management 68: [2277, 2311]\n",
      "âœ… MBA Healthcare Management 69: [2277, 2311]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Elementary Education (K-8) 122: [2277, 2311]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Mathematics (5-9) 123: [2277, 2311]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Mathematics (5-12) 124: [2277, 2311]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Science (5-9) 125: [2277, 2311]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Science (5-12) 126: [2277, 2311]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Social Science (5-12) 127: [2277, 2311]\n",
      "âœ… Endorsement Preparation Program, Educational Leadership 149: [2277, 2311]\n",
      "âœ… Endorsement Preparation Program, English Language Learning (PreK-12) 150: [2277, 2311]\n",
      "âœ… MBA, Harvard Ph.D., University of Arizona: [2277, 2311]\n",
      "âœ… MBA, Western Governors University Ph.D., Brigham Young University: [2277, 2311]\n",
      "âœ… postsecondary school required under 34 C.F.R. 600.9 to be legally authorized by the State of Utah.: [2277, 2311]\n",
      "âœ… posting of course results by the last day of the term.: [2277, 2311]\n",
      "âœ… Bachelor of Science, Business Management: [2277, 2311]\n",
      "\n",
      "ðŸ“… Processing: 2017-05\n",
      "âœ… Master of Business Administration 67: [2277, 2311]\n",
      "âœ… MBA Information Technology Management 68: [2277, 2311]\n",
      "âœ… MBA Healthcare Management 69: [2277, 2311]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Elementary Education (K-8) 122: [2277, 2311]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Mathematics (5-9) 123: [2277, 2311]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Mathematics (5-12) 124: [2277, 2311]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Science (5-9) 125: [2277, 2311]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Science (5-12) 126: [2277, 2311]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Social Science (5-12) 127: [2277, 2311]\n",
      "âœ… Endorsement Preparation Program, Educational Leadership 149: [2277, 2311]\n",
      "âœ… Endorsement Preparation Program, English Language Learning (PreK-12) 150: [2277, 2311]\n",
      "âœ… MBA, Harvard Ph.D., University of Arizona: [2277, 2311]\n",
      "âœ… MBA, Western Governors University Ph.D., Brigham Young University: [2277, 2311]\n",
      "âœ… postsecondary school required under 34 C.F.R. 600.9 to be legally authorized by the State of Utah.: [2277, 2311]\n",
      "âœ… posting of course results by the last day of the term.: [2277, 2311]\n",
      "âœ… Bachelor of Science, Business Management: [2277, 2311]\n",
      "\n",
      "ðŸ“… Processing: 2017-07\n",
      "âœ… Master of Business Administration 67: [2285, 2319]\n",
      "âœ… MBA Information Technology Management 68: [2285, 2319]\n",
      "âœ… MBA Healthcare Management 69: [2285, 2319]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Elementary Education 124: [2285, 2319]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Science (5-12) 125: [2285, 2319]\n",
      "âœ… Endorsement Preparation Program, Educational Leadership 145: [2285, 2319]\n",
      "âœ… Endorsement Preparation Program, English Language Learning (ELL) (PreK-12) 146: [2285, 2319]\n",
      "âœ… MBA, Harvard Ph.D., Brigham Young University: [2285, 2319]\n",
      "âœ… MBA, Western Governors University Ed.D., University of North Texas: [2285, 2319]\n",
      "âœ… MBA, American InterContinental University MPA, University of Phoenix: [2285, 2319]\n",
      "âœ… MBA, DeVry University: [2285, 2319]\n",
      "âœ… postsecondary school required under 34 C.F.R. 600.9 to be legally authorized by the State of Utah.: [2285, 2319]\n",
      "âœ… posting of course results by the last day of the term.: [2285, 2319]\n",
      "âœ… Bachelor of Science, Business Management: [2285, 2319]\n",
      "\n",
      "ðŸ“… Processing: 2017-08\n",
      "âœ… Master of Business Administration 67: [2239, 2273]\n",
      "âœ… MBA Information Technology Management 68: [2239, 2273]\n",
      "âœ… MBA Healthcare Management 69: [2239, 2273]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Elementary Education 124: [2239, 2273]\n",
      "âœ… Post-Baccalaureate Teacher Preparation, Science (5-12) 125: [2239, 2273]\n",
      "âœ… Endorsement Preparation Program, Educational Leadership 145: [2239, 2273]\n",
      "âœ… Endorsement Preparation Program, English Language Learning (ELL) (PreK-12) 146: [2239, 2273]\n",
      "âœ… MBA, Harvard Ph.D., Brigham Young University: [2239, 2273]\n",
      "âœ… MBA, Western Governors University Ed.D., University of North Texas: [2239, 2273]\n",
      "âœ… MBA, American InterContinental University MPA, University of Phoenix: [2239, 2273]\n",
      "âœ… MBA, American InterContinental University: [2239, 2273]\n",
      "âœ… postsecondary school required under 34 C.F.R. 600.9 to be legally authorized by the State of Utah.: [2239, 2273]\n",
      "âœ… posting of course results by the last day of the term.: [2239, 2273]\n",
      "âœ… Bachelor of Science, Business Management: [2239, 2273]\n",
      "\n",
      "âœ… sections_index_v10.json saved: ../WGU_catalog/helpers/sections_index_v10.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================\n",
    "Scraper_V10 â€” Build Verified Degree Fences (V10 Locked)\n",
    "----------------------------------------------------------------\n",
    "Purpose:\n",
    "  - For each parsed catalog:\n",
    "      - Use trusted { College â†’ Degree } from program_names_v10.json.\n",
    "      - Find Degree name in .txt.\n",
    "      - Walk FORWARD to pin first CCN_HEADER for that Degree.\n",
    "      - Fence stops at:\n",
    "          - Next Degree name,\n",
    "          - Next College name,\n",
    "          - Known footer anchor,\n",
    "          - Or EOF.\n",
    "  - Logs any Degree missing CCN block.\n",
    "  - Produces: sections_index_v10.json â†’ single truth for Degree fences.\n",
    "================================================================\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "# === Anchors ===\n",
    "ANCHOR_CCN_HEADER = re.compile(r\"CCN.*Course Number\", re.IGNORECASE)\n",
    "ANCHOR_COLLEGE = re.compile(r\"College of \", re.IGNORECASE)\n",
    "ANCHOR_TOTAL_CUS = re.compile(r\"Total CUs\", re.IGNORECASE)\n",
    "ANCHOR_COPYRIGHT = re.compile(r\"Â©\")\n",
    "\n",
    "# === Directories ===\n",
    "TEXT_DIR = \"../WGU_catalog/catalogs/plumber_parsed/\"\n",
    "PROGRAM_NAMES_DIR = \"../WGU_catalog/outputs/program_names/\"\n",
    "OUTPUT_SECTIONS_INDEX = \"../WGU_catalog/helpers/sections_index_v10.json\"\n",
    "\n",
    "sections_index = {}\n",
    "\n",
    "catalog_files = sorted([f for f in os.listdir(TEXT_DIR) if f.endswith(\".txt\")])\n",
    "\n",
    "for FILE_NAME in catalog_files:\n",
    "    FILE_PATH = os.path.join(TEXT_DIR, FILE_NAME)\n",
    "    DATE_PART = FILE_NAME.replace(\".txt\", \"\").split(\"_\")[1:]\n",
    "    CATALOG_DATE = f\"{DATE_PART[0]}-{DATE_PART[1]}\"\n",
    "    print(f\"\\nðŸ“… Processing: {CATALOG_DATE}\")\n",
    "\n",
    "    # === Load Degree names ===\n",
    "    degree_names_path = os.path.join(PROGRAM_NAMES_DIR, f\"{DATE_PART[0]}_{DATE_PART[1]}_program_names_v10.json\")\n",
    "    if not os.path.exists(degree_names_path):\n",
    "        print(f\"âŒ No Degree names JSON for {CATALOG_DATE} â€” skipping.\")\n",
    "        continue\n",
    "\n",
    "    with open(degree_names_path, 'r') as f:\n",
    "        degree_names = json.load(f)\n",
    "\n",
    "    # === Load lines ===\n",
    "    with open(FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        lines = [l.strip() for l in f]\n",
    "\n",
    "    sections_index.setdefault(CATALOG_DATE, {})\n",
    "\n",
    "    for college, programs in degree_names.items():\n",
    "        sections_index[CATALOG_DATE].setdefault(college, {})\n",
    "\n",
    "        for degree_name in programs:\n",
    "            start_idx = None\n",
    "            stop_idx = len(lines)\n",
    "\n",
    "            # === 1. Find Degree heading ===\n",
    "            degree_heading_idx = None\n",
    "            for i, line in enumerate(lines):\n",
    "                if line == degree_name:\n",
    "                    degree_heading_idx = i\n",
    "                    break\n",
    "            if degree_heading_idx is None:\n",
    "                print(f\"âš ï¸  Degree name not found: {degree_name} in {catalog_date} ({college})\")\n",
    "                continue\n",
    "\n",
    "            # === 2. Forward scan to first CCN_HEADER ===\n",
    "            for j in range(degree_heading_idx, len(lines)):\n",
    "                if ANCHOR_CCN_HEADER.search(lines[j]):\n",
    "                    start_idx = j\n",
    "                    break\n",
    "            if start_idx is None:\n",
    "                print(f\"âš ï¸  No CCN table found for: {degree_name} in {catalog_date} ({college})\")\n",
    "                continue\n",
    "\n",
    "            # === 3. Find stop fence ===\n",
    "            for k in range(start_idx + 1, len(lines)):\n",
    "                next_line = lines[k].strip()\n",
    "                if next_line in programs and next_line != degree_name:\n",
    "                    stop_idx = k\n",
    "                    break\n",
    "                if ANCHOR_COLLEGE.search(next_line):\n",
    "                    stop_idx = k\n",
    "                    break\n",
    "                if ANCHOR_TOTAL_CUS.search(next_line) or ANCHOR_COPYRIGHT.search(next_line):\n",
    "                    stop_idx = k\n",
    "                    break\n",
    "\n",
    "            sections_index[CATALOG_DATE][college][degree_name] = [start_idx, stop_idx]\n",
    "            print(f\"âœ… {degree_name}: [{start_idx}, {stop_idx}]\")\n",
    "\n",
    "# === Save final fences ===\n",
    "with open(OUTPUT_SECTIONS_INDEX, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sections_index, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… sections_index_v10.json saved: {OUTPUT_SECTIONS_INDEX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "adc31baf-d5d9-4548-aca9-8529c3ba3ba3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[FAIL] Expected College 'College of Business' not found in parsed output for 2017-01 (using snapshot version 2017-01)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[236]\u001b[39m\u001b[32m, line 102\u001b[39m\n\u001b[32m    100\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m college == \u001b[33m\"\u001b[39m\u001b[33mCertificates - Standard Paths\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    101\u001b[39m                 \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Optional trailing block\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    103\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[FAIL] Expected College \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollege\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not found in parsed output for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcatalog_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    104\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(using snapshot version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msnapshot_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    105\u001b[39m             )\n\u001b[32m    107\u001b[39m     degree_snapshots[catalog_date] = snapshot_ordered\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# === Save final Degree snapshot ===\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: [FAIL] Expected College 'College of Business' not found in parsed output for 2017-01 (using snapshot version 2017-01)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================\n",
    "Scraper_V10 â€” Build Verified Degree Snapshots (V10 Locked)\n",
    "----------------------------------------------------------------\n",
    "Purpose:\n",
    "  - Consolidate all raw parsed program names per catalog.\n",
    "  - Resolve Degree name duplicates using trusted master map.\n",
    "  - Enforce unique placement for Certificates:\n",
    "      â€¢ Embedded in Colleges.\n",
    "      â€¢ Or fenced separately as trailing Certificates.\n",
    "  - Strictly match canonical College order from snapshot.\n",
    "  - Output:\n",
    "      â€¢ degree_snapshots_v10_seed.json â†’ single truth for Degree lists.\n",
    "  - Fails if:\n",
    "      â€¢ Any Certificate appears in both embedded and trailing.\n",
    "      â€¢ Any expected College is missing from parsed output.\n",
    "================================================================\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# === Paths ===\n",
    "OUTPUT_DIR = Path(\"../WGU_catalog/outputs/program_names/\")\n",
    "HELPERS_DIR = Path(\"../WGU_catalog/helpers/\")\n",
    "\n",
    "COLLEGE_SNAPSHOTS_FILE = HELPERS_DIR / \"college_snapshots.json\"\n",
    "DEGREE_DUPLICATES_FILE = HELPERS_DIR / \"degree_duplicates_master_v10.json\"\n",
    "DEGREE_SNAPSHOTS_OUT_FILE = HELPERS_DIR / \"degree_snapshots_v10_seed.json\"\n",
    "\n",
    "# === Load trusted references ===\n",
    "with open(COLLEGE_SNAPSHOTS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    college_snapshots = json.load(f)\n",
    "\n",
    "with open(DEGREE_DUPLICATES_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    degree_duplicates = json.load(f)\n",
    "\n",
    "degree_snapshots = {}\n",
    "\n",
    "# === Determine snapshot versions ===\n",
    "snapshot_versions = sorted(college_snapshots.keys())\n",
    "\n",
    "def pick_snapshot(catalog_date):\n",
    "    chosen = None\n",
    "    for version in snapshot_versions:\n",
    "        if version <= catalog_date:\n",
    "            chosen = version\n",
    "    if not chosen:\n",
    "        raise ValueError(f\"[FAIL] No valid College snapshot found for {catalog_date}\")\n",
    "    return chosen\n",
    "\n",
    "# === Process each parsed program_names_v10.json ===\n",
    "for program_file in sorted(OUTPUT_DIR.glob(\"*_program_names_v10.json\")):\n",
    "    catalog_date = program_file.stem.split(\"_program_names_v10\")[0].replace(\"_\", \"-\")\n",
    "\n",
    "    with open(program_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        program_names = json.load(f)\n",
    "\n",
    "    snapshot_version = pick_snapshot(catalog_date)\n",
    "    canonical_order = college_snapshots[snapshot_version]\n",
    "\n",
    "    snapshot_unsorted = {}\n",
    "    embedded_certificates = set()\n",
    "    trailing_certificates = []\n",
    "\n",
    "    for college_name, degrees in program_names.items():\n",
    "        resolved_degrees = []\n",
    "        for degree in degrees:\n",
    "            degree = degree.strip()\n",
    "            if degree in degree_duplicates:\n",
    "                degree = degree_duplicates[degree]\n",
    "            resolved_degrees.append(degree)\n",
    "\n",
    "        if college_name == \"Certificates - Standard Paths\":\n",
    "            trailing_certificates.extend(resolved_degrees)\n",
    "        else:\n",
    "            unique_sorted = sorted(set(resolved_degrees))\n",
    "            snapshot_unsorted[college_name] = unique_sorted\n",
    "\n",
    "            for degree in unique_sorted:\n",
    "                if \"Certificate\" in degree:\n",
    "                    embedded_certificates.add(degree)\n",
    "\n",
    "    if trailing_certificates:\n",
    "        trailing_certificates = sorted(set(trailing_certificates))\n",
    "        overlap = embedded_certificates.intersection(trailing_certificates)\n",
    "        if overlap:\n",
    "            raise ValueError(\n",
    "                f\"[FAIL] Overlapping Certificates found in both embedded Colleges \"\n",
    "                f\"and trailing Certificates - Standard Paths for {catalog_date}: {overlap}\"\n",
    "            )\n",
    "        snapshot_unsorted[\"Certificates - Standard Paths\"] = trailing_certificates\n",
    "\n",
    "    # === Enforce canonical College order ===\n",
    "    snapshot_ordered = {}\n",
    "    for college in canonical_order:\n",
    "        if college in snapshot_unsorted:\n",
    "            snapshot_ordered[college] = snapshot_unsorted[college]\n",
    "        else:\n",
    "            if college == \"Certificates - Standard Paths\":\n",
    "                continue  # Optional trailing block\n",
    "            raise ValueError(\n",
    "                f\"[FAIL] Expected College '{college}' not found in parsed output for {catalog_date} \"\n",
    "                f\"(using snapshot version {snapshot_version})\"\n",
    "            )\n",
    "\n",
    "    degree_snapshots[catalog_date] = snapshot_ordered\n",
    "\n",
    "# === Save final Degree snapshot ===\n",
    "with open(DEGREE_SNAPSHOTS_OUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(degree_snapshots, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"[PASS] degree_snapshots_v10_seed.json built successfully â†’ {DEGREE_SNAPSHOTS_OUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "068be8d1-d6b8-4877-9537-5b934c92172c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../WGU_catalog/helpers/course_index_v10.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[237]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m     15\u001b[39m COURSE_INDEX_PATH = \u001b[33m\"\u001b[39m\u001b[33m../WGU_catalog/helpers/course_index_v10.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCOURSE_INDEX_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     18\u001b[39m     course_index = json.load(f)\n\u001b[32m     20\u001b[39m total_unique = \u001b[38;5;28mlen\u001b[39m(course_index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/WGU-Reddit/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../WGU_catalog/helpers/course_index_v10.json'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================\n",
    "Scraper_V10 â€” Count Unique Canonical Courses\n",
    "----------------------------------------------------------------\n",
    "Loads:\n",
    "  - course_index_v10.json\n",
    "Returns:\n",
    "  - Total unique CCNs (or Course Codes if CCN is null)\n",
    "  - Prints top examples for spot check.\n",
    "----------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "COURSE_INDEX_PATH = \"../WGU_catalog/helpers/course_index_v10.json\"\n",
    "\n",
    "with open(COURSE_INDEX_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    course_index = json.load(f)\n",
    "\n",
    "total_unique = len(course_index)\n",
    "\n",
    "print(f\"âœ… Total Unique Canonical Courses (CCNs or Codes): {total_unique}\\n\")\n",
    "\n",
    "# Peek at first few\n",
    "print(\"--- Sample ---\")\n",
    "for i, (ccn, info) in enumerate(course_index.items()):\n",
    "    print(f\"{ccn} â†’ {info['canonical_title']} (CUs: {info['canonical_cus']})\")\n",
    "    if i >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd98e1-98f4-44cc-9784-ded1cbbb0e0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1e9ca0-63a4-4972-b9d8-b6c94033db33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dbcb93-d95a-462c-a9d1-55107a9d5fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c811d5f5-226d-4777-9698-f0baa3aa101f",
   "metadata": {},
   "source": [
    "## create degree snapshot, incl. certs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83560e0-459c-4743-a733-c4a52401b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIG ===\n",
    "OUTPUT_DIR = Path(\"../WGU_catalog/outputs/program_names/\")\n",
    "helpers_dir = Path(\"../WGU_catalog/helpers/\")\n",
    "\n",
    "college_snapshots_file = helpers_dir / \"college_snapshots.json\"\n",
    "degree_duplicates_file = helpers_dir / \"degree_duplicates_master_v10.json\"\n",
    "degree_snapshots_out_file = helpers_dir / \"degree_snapshots_v10_seed.json\"\n",
    "\n",
    "# === LOAD ===\n",
    "with open(college_snapshots_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    college_snapshots = json.load(f)\n",
    "\n",
    "with open(degree_duplicates_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    degree_duplicates = json.load(f)\n",
    "\n",
    "degree_snapshots = {}\n",
    "\n",
    "# === Prepare sorted snapshot versions ===\n",
    "snapshot_versions = sorted(college_snapshots.keys())\n",
    "\n",
    "def pick_snapshot(catalog_date):\n",
    "    chosen = None\n",
    "    for version in snapshot_versions:\n",
    "        if version <= catalog_date:\n",
    "            chosen = version\n",
    "    if not chosen:\n",
    "        raise ValueError(f\"[FAIL] No valid college snapshot found for {catalog_date}\")\n",
    "    return chosen\n",
    "\n",
    "# === PROCESS EACH PROGRAM FILE ===\n",
    "for program_file in sorted(OUTPUT_DIR.glob(\"*_program_names_v10.json\")):\n",
    "    catalog_date = program_file.stem.split(\"_program_names_v10\")[0].replace(\"_\", \"-\")\n",
    "\n",
    "    with open(program_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        program_names = json.load(f)\n",
    "\n",
    "    snapshot_version = pick_snapshot(catalog_date)\n",
    "    canonical_order = college_snapshots[snapshot_version]\n",
    "\n",
    "    snapshot_unsorted = {}\n",
    "    embedded_certificates = set()\n",
    "    trailing_certificates = []\n",
    "\n",
    "    for college_name, degrees in program_names.items():\n",
    "        resolved_degrees = []\n",
    "        for degree in degrees:\n",
    "            degree = degree.strip()\n",
    "            if degree in degree_duplicates:\n",
    "                degree = degree_duplicates[degree]\n",
    "            resolved_degrees.append(degree)\n",
    "\n",
    "        if college_name == \"Certificates - Standard Paths\":\n",
    "            trailing_certificates.extend(resolved_degrees)\n",
    "        else:\n",
    "            unique_sorted = sorted(set(resolved_degrees))\n",
    "            snapshot_unsorted[college_name] = unique_sorted\n",
    "\n",
    "            for degree in unique_sorted:\n",
    "                if \"Certificate\" in degree:\n",
    "                    embedded_certificates.add(degree)\n",
    "\n",
    "    if trailing_certificates:\n",
    "        trailing_certificates = sorted(set(trailing_certificates))\n",
    "        overlap = embedded_certificates.intersection(trailing_certificates)\n",
    "        if overlap:\n",
    "            raise ValueError(\n",
    "                f\"[FAIL] Overlapping Certificates found in embedded Colleges \"\n",
    "                f\"and trailing Certificates - Standard Paths for {catalog_date}: {overlap}\"\n",
    "            )\n",
    "        snapshot_unsorted[\"Certificates - Standard Paths\"] = trailing_certificates\n",
    "\n",
    "    # === Reorder according to canonical College order ===\n",
    "    snapshot_ordered = {}\n",
    "    for college in canonical_order:\n",
    "        if college in snapshot_unsorted:\n",
    "            snapshot_ordered[college] = snapshot_unsorted[college]\n",
    "        else:\n",
    "            if college == \"Certificates - Standard Paths\":\n",
    "                continue\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"[FAIL] Expected College '{college}' not found in parsed output for {catalog_date} \"\n",
    "                    f\"(using snapshot version {snapshot_version})\"\n",
    "                )\n",
    "\n",
    "    degree_snapshots[catalog_date] = snapshot_ordered\n",
    "\n",
    "# === SAVE FINAL SNAPSHOT ===\n",
    "with open(degree_snapshots_out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(degree_snapshots, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"[PASS] degree_snapshots_v10_seed.json built successfully at {degree_snapshots_out_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697fcec9-c228-4c4d-b3d7-1625c6a049bf",
   "metadata": {},
   "source": [
    "## Flatten Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "72367a10-4f95-42d8-9d47-e7856209143e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../WGU_catalog/outputs/courses_flat_v10.csv (1328 rows)\n",
      "  CourseCode                CourseName\n",
      "0       C711  Introduction to Business\n",
      "1       C455     English Composition I\n",
      "2       C268              Spreadsheets\n",
      "3       C463      Intermediate Algebra\n",
      "4       C715   Organizational Behavior\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "COURSE_INDEX_PATH = \"../WGU_catalog/helpers/course_index_v10.json\"\n",
    "OUTPUT_CSV_PATH = \"../WGU_catalog/outputs/courses_flat_v10.csv\"\n",
    "\n",
    "# Load course index\n",
    "with open(COURSE_INDEX_PATH, \"r\") as f:\n",
    "    course_index = json.load(f)\n",
    "\n",
    "# Prepare rows: only CourseCode and CourseName\n",
    "rows = []\n",
    "for ccn, details in course_index.items():\n",
    "    row = {\n",
    "        \"CourseCode\": ccn.strip(),\n",
    "        \"CourseName\": details.get(\"canonical_title\", \"\").strip()\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "# Write CSV\n",
    "with open(OUTPUT_CSV_PATH, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"CourseCode\", \"CourseName\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Saved: {OUTPUT_CSV_PATH} ({len(rows)} rows)\")\n",
    "\n",
    "# Load and preview\n",
    "df_courses = pd.read_csv(OUTPUT_CSV_PATH)\n",
    "print(df_courses.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef4a38f-3940-4015-b935-ea2c4e389b53",
   "metadata": {},
   "source": [
    "## Output Course Code, Name, College(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b1ba72c9-9181-4f83-97a5-85c063f8b3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../WGU_catalog/outputs/courses_with_college_v10.csv (1328 rows)\n",
      "  CourseCode                CourseName  \\\n",
      "0       C711  Introduction to Business   \n",
      "1       C455     English Composition I   \n",
      "2       C268              Spreadsheets   \n",
      "3       C463      Intermediate Algebra   \n",
      "4       C715   Organizational Behavior   \n",
      "\n",
      "                                            Colleges  \n",
      "0                                College of Business  \n",
      "1  College of Business; College of Health Profess...  \n",
      "2  College of Business; College of Information Te...  \n",
      "3  College of Business; College of Health Profess...  \n",
      "4  College of Business; College of Health Profess...  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "COURSE_INDEX_PATH = \"../WGU_catalog/helpers/course_index_v10.json\"\n",
    "OUTPUT_CSV_PATH = \"../WGU_catalog/outputs/courses_with_college_v10.csv\"\n",
    "\n",
    "# Load course index\n",
    "with open(COURSE_INDEX_PATH, \"r\") as f:\n",
    "    course_index = json.load(f)\n",
    "\n",
    "# Prepare rows: CourseCode, CourseName, Colleges (joined)\n",
    "rows = []\n",
    "for ccn, details in course_index.items():\n",
    "    colleges = set()\n",
    "    for inst in details.get(\"instances\", []):\n",
    "        college = inst.get(\"college\", \"\").strip()\n",
    "        if college:\n",
    "            colleges.add(college)\n",
    "    colleges_str = \"; \".join(sorted(colleges)) if colleges else \"\"\n",
    "    row = {\n",
    "        \"CourseCode\": ccn.strip(),\n",
    "        \"CourseName\": details.get(\"canonical_title\", \"\").strip(),\n",
    "        \"Colleges\": colleges_str\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "# Write CSV\n",
    "with open(OUTPUT_CSV_PATH, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"CourseCode\", \"CourseName\", \"Colleges\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Saved: {OUTPUT_CSV_PATH} ({len(rows)} rows)\")\n",
    "\n",
    "# Load and preview\n",
    "df_courses = pd.read_csv(OUTPUT_CSV_PATH)\n",
    "print(df_courses.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a3a5ef-a106-4399-b455-629597da33d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db5744-9e2c-470e-9461-82311b4a8553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77091bf-7f54-48d1-8562-e93483d0cc90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdbbea6-148b-46c0-abd7-e22b24f70703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cead99e-90dc-40e2-a869-27e01c3de2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Batch parse all catalogs, extract raw course rows, run regex, split valid/anomalies, save all\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "# === CONFIG ===\n",
    "INPUT_DIR = \"../WGU_catalog/catalogs/plumber_parsed/\"\n",
    "OUTPUT_DIR = \"../WGU_catalog/outputs/raw_course_rows/\"\n",
    "ANOMALY_DIR = \"../WGU_catalog/outputs/anomalies/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(ANOMALY_DIR, exist_ok=True)\n",
    "\n",
    "# Anchors\n",
    "ANCHOR_CCN_HEADER = re.compile(r'^CCN\\s+Course Number\\s+Course Description\\s+CUs\\s+Term', re.I)\n",
    "ANCHOR_TOTAL_CUS = re.compile(r'^Total CUs', re.I)\n",
    "ANCHOR_FOOTER_COPYRIGHT = re.compile(r'Â© Western Governors University', re.I)\n",
    "\n",
    "# Regex: CCN Table Header mapping\n",
    "pattern = re.compile(r'^([A-Z]{2,5})\\s+(\\d{1,4})\\s+([A-Z0-9]{2,5})\\s+(.+?)\\s+(\\d+)\\s+(\\d+)$')\n",
    "\n",
    "# === Load college snapshot\n",
    "with open('../WGU_catalog/helpers/college_snapshots.json', 'r') as f:\n",
    "    college_snapshots = json.load(f)\n",
    "\n",
    "def pick_snapshot(date):\n",
    "    versions = sorted(college_snapshots.keys())\n",
    "    chosen = None\n",
    "    for v in versions:\n",
    "        if v <= date:\n",
    "            chosen = v\n",
    "    if not chosen:\n",
    "        raise ValueError(f\"No snapshot found for {date}\")\n",
    "    return college_snapshots[chosen]\n",
    "\n",
    "# === Process each .txt file ===\n",
    "for filename in sorted(os.listdir(INPUT_DIR)):\n",
    "    if not filename.endswith('.txt'):\n",
    "        continue\n",
    "\n",
    "    FILE_PATH = os.path.join(INPUT_DIR, filename)\n",
    "    parts = filename.replace(\".txt\", \"\").split(\"_\")\n",
    "    DATE_PART = f\"{parts[1]}_{parts[2]}\"\n",
    "    CATALOG_DATE = f\"{parts[1]}-{parts[2]}\"\n",
    "    print(f\"\\nðŸ“˜ Processing: {filename} | Catalog Date: {CATALOG_DATE}\")\n",
    "\n",
    "    # === Load snapshot for date ===\n",
    "    valid_colleges = pick_snapshot(CATALOG_DATE)\n",
    "    print(f\"Snapshot: {valid_colleges}\")\n",
    "\n",
    "    # === Read lines ===\n",
    "    with open(FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        lines = [l.strip() for l in f]\n",
    "\n",
    "    # === Find program section ===\n",
    "    def get_program_section_start(lines, valid_colleges):\n",
    "        first_ccn_idx = None\n",
    "        for i, line in enumerate(lines):\n",
    "            if ANCHOR_CCN_HEADER.search(line):\n",
    "                first_ccn_idx = i\n",
    "                break\n",
    "        if first_ccn_idx is None:\n",
    "            raise ValueError(\"No CCN header found\")\n",
    "\n",
    "        for j in range(first_ccn_idx, -1, -1):\n",
    "            if lines[j].strip() in valid_colleges:\n",
    "                return j\n",
    "        raise ValueError(\"No College header found above first CCN\")\n",
    "\n",
    "    PROGRAM_SECTION_START = get_program_section_start(lines, valid_colleges)\n",
    "    lines_to_scan = lines[PROGRAM_SECTION_START:]\n",
    "\n",
    "    # === Find all CCN header indices ===\n",
    "    ccn_indices = [i for i, line in enumerate(lines_to_scan) if ANCHOR_CCN_HEADER.search(line)]\n",
    "    print(f\"Found {len(ccn_indices)} CCN tables\")\n",
    "\n",
    "    # === Extract raw rows ===\n",
    "    raw_course_rows = []\n",
    "    for idx, anchor_idx in enumerate(ccn_indices):\n",
    "        block_start = anchor_idx + 1\n",
    "        block_end = len(lines_to_scan)\n",
    "\n",
    "        # Look for next CCN header\n",
    "        if idx + 1 < len(ccn_indices):\n",
    "            block_end = ccn_indices[idx + 1]\n",
    "\n",
    "        for i in range(block_start, block_end):\n",
    "            line = lines_to_scan[i]\n",
    "            if ANCHOR_TOTAL_CUS.search(line) or ANCHOR_FOOTER_COPYRIGHT.search(line):\n",
    "                block_end = i\n",
    "                break\n",
    "\n",
    "        for i in range(block_start, block_end):\n",
    "            raw_line = lines_to_scan[i].strip()\n",
    "            if raw_line:\n",
    "                raw_course_rows.append(raw_line)\n",
    "\n",
    "    print(f\"Total raw rows: {len(raw_course_rows)}\")\n",
    "\n",
    "    # === Classify rows ===\n",
    "    valid_rows = []\n",
    "    anomalies = []\n",
    "    for row in raw_course_rows:\n",
    "        if pattern.match(row):\n",
    "            valid_rows.append(row)\n",
    "        else:\n",
    "            anomalies.append(row)\n",
    "\n",
    "    print(f\"Valid: {len(valid_rows)} | Anomalies: {len(anomalies)}\")\n",
    "\n",
    "    # === Save ===\n",
    "    output_raw = os.path.join(OUTPUT_DIR, f\"{DATE_PART}_raw_course_rows_v10.json\")\n",
    "    output_anomaly = os.path.join(ANOMALY_DIR, f\"anomalies_{DATE_PART}_v10.json\")\n",
    "\n",
    "    with open(output_raw, 'w', encoding='utf-8') as f:\n",
    "        json.dump(raw_course_rows, f, indent=2)\n",
    "\n",
    "    with open(output_anomaly, 'w', encoding='utf-8') as f:\n",
    "        json.dump(anomalies, f, indent=2)\n",
    "\n",
    "    print(f\"âœ… Saved raw to {output_raw}\")\n",
    "    print(f\"âœ… Saved anomalies to {output_anomaly}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a79dec-8281-4db8-bd6e-52e00bdd4a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202420b8-0ada-46cb-9130-176eb0a3af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible updated fence builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe5ed35-b2a1-41b0-97a7-aee369511c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "Purpose: Build Degree Fences â†’ sections_index_v10.json (V10)\n",
    "------------------------------------------------------------\n",
    "\n",
    "Description:\n",
    "  - For each parsed catalog (.txt), find exact start/stop lines \n",
    "    for every verified {College â†’ Degree}.\n",
    "  - Uses trusted Degree name lists (program_names_v10.json).\n",
    "  - Stops at next Degree, next College, forced footer, or EOF.\n",
    "\n",
    "Output:\n",
    "  - sections_index_v10.json:\n",
    "      {Catalog Date â†’ College â†’ Degree â†’ [start_line, stop_line]}\n",
    "\n",
    "Why:\n",
    "  - Defines strict Degree block boundaries for Course parsing.\n",
    "  - Enables stray course row detection outside known fences.\n",
    "  - Supports unit tests for fence integrity.\n",
    "  - All forced boundary exceptions must be logged in \n",
    "    catalog_schema_notes_v10.md.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "TEXT_DIR = \"../WGU_catalog/catalogs/plumber_parsed/\"\n",
    "PROGRAM_NAMES_DIR = \"../WGU_catalog/outputs/program_names/\"\n",
    "OUTPUT_SECTIONS_INDEX = \"../WGU_catalog/helpers/sections_index_v10.json\"\n",
    "\n",
    "# === Anchors ===\n",
    "ANCHOR_DEGREE_HEADER = re.compile(r\"^(Bachelor|Master|Certificate|Post|Endorsement|MBA|MS,|BS,)\", re.IGNORECASE)\n",
    "ANCHOR_COLLEGE = re.compile(r\"(College of .+)\", re.IGNORECASE)\n",
    "ANCHOR_TOTAL_CUS = re.compile(r\"Total CUs\", re.IGNORECASE)\n",
    "ANCHOR_COPYRIGHT = re.compile(r\"Â©\")\n",
    "\n",
    "sections_index = {}\n",
    "\n",
    "catalog_files = sorted([f for f in os.listdir(TEXT_DIR) if f.endswith(\".txt\")])\n",
    "\n",
    "for FILE_NAME in catalog_files:\n",
    "    FILE_PATH = os.path.join(TEXT_DIR, FILE_NAME)\n",
    "    DATE_PART = FILE_NAME.replace(\".txt\", \"\").split(\"_\")[1:]\n",
    "    CATALOG_DATE = f\"{DATE_PART[0]}-{DATE_PART[1]}\"\n",
    "    print(f\"\\nðŸ“… Processing: {CATALOG_DATE}\")\n",
    "\n",
    "    # === Load Degree names ===\n",
    "    degree_names_path = os.path.join(PROGRAM_NAMES_DIR, f\"{DATE_PART[0]}_{DATE_PART[1]}_program_names_v10.json\")\n",
    "    if not os.path.exists(degree_names_path):\n",
    "        print(f\"âŒ No Degree names JSON for {CATALOG_DATE} â€” skipping.\")\n",
    "        continue\n",
    "\n",
    "    with open(degree_names_path, 'r') as f:\n",
    "        degree_names = json.load(f)\n",
    "\n",
    "    # === Load lines ===\n",
    "    with open(FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        lines = [l.strip() for l in f]\n",
    "\n",
    "    sections_index.setdefault(CATALOG_DATE, {})\n",
    "\n",
    "    for college, programs in degree_names.items():\n",
    "        sections_index[CATALOG_DATE].setdefault(college, {})\n",
    "\n",
    "        for program_name in programs:\n",
    "            # === Find start line ===\n",
    "            start_idx = None\n",
    "            for i, line in enumerate(lines):\n",
    "                if line == program_name:\n",
    "                    start_idx = i\n",
    "                    break\n",
    "            if start_idx is None:\n",
    "                print(f\"âš ï¸  Degree not found: {program_name} in {CATALOG_DATE} ({college})\")\n",
    "                continue\n",
    "\n",
    "            # === Find stop line ===\n",
    "            stop_idx = len(lines)  # default to EOF\n",
    "            for j in range(start_idx + 1, len(lines)):\n",
    "                next_line = lines[j].strip()\n",
    "                if next_line in programs and next_line != program_name:\n",
    "                    stop_idx = j\n",
    "                    break\n",
    "                if any(next_line == c for c in degree_names.keys()):  # next College header\n",
    "                    stop_idx = j\n",
    "                    break\n",
    "                if ANCHOR_TOTAL_CUS.search(next_line) or ANCHOR_COPYRIGHT.search(next_line):\n",
    "                    stop_idx = j\n",
    "                    break\n",
    "\n",
    "            sections_index[CATALOG_DATE][college][program_name] = [start_idx, stop_idx]\n",
    "\n",
    "print(\"\\nâœ… Degree fences built.\")\n",
    "with open(OUTPUT_SECTIONS_INDEX, \"w\") as f:\n",
    "    json.dump(sections_index, f, indent=2)\n",
    "\n",
    "print(f\"\\nðŸ“‚ Saved: {OUTPUT_SECTIONS_INDEX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a2cc06-02aa-4bed-927d-a9211c92ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------------\n",
    "V10 Fence Spot Check â€” Global Extremes\n",
    "------------------------------------------------------------\n",
    "\n",
    "Purpose:\n",
    "  Find the few shortest and longest Degree blocks across all catalogs.\n",
    "  Confirms no accidental overlap or underfencing.\n",
    "  Shows lines and preview text for manual inspection.\n",
    "\n",
    "Adjust:\n",
    "  N = how many to show for each end.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "TEXT_DIR = \"../WGU_catalog/catalogs/plumber_parsed/\"\n",
    "SECTIONS_INDEX_PATH = \"../WGU_catalog/helpers/sections_index_v10.json\"\n",
    "\n",
    "N = 5  # Number of shortest and longest to show\n",
    "\n",
    "# === Load fences ===\n",
    "with open(SECTIONS_INDEX_PATH, \"r\") as f:\n",
    "    sections_index = json.load(f)\n",
    "\n",
    "# === Gather all Degree blocks across all catalogs ===\n",
    "all_blocks = []\n",
    "\n",
    "for FILE_NAME in sorted(os.listdir(TEXT_DIR)):\n",
    "    if not FILE_NAME.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    FILE_PATH = os.path.join(TEXT_DIR, FILE_NAME)\n",
    "    DATE_PART = FILE_NAME.replace(\".txt\", \"\").split(\"_\")[1:]\n",
    "    CATALOG_DATE = f\"{DATE_PART[0]}-{DATE_PART[1]}\"\n",
    "\n",
    "    if CATALOG_DATE not in sections_index:\n",
    "        continue\n",
    "\n",
    "    with open(FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        lines = [l.strip() for l in f]\n",
    "\n",
    "    fences = sections_index[CATALOG_DATE]\n",
    "\n",
    "    for college, degrees in fences.items():\n",
    "        for degree_name, (start_idx, stop_idx) in degrees.items():\n",
    "            block_len = stop_idx - start_idx\n",
    "            snippet = lines[start_idx:stop_idx]\n",
    "            preview = snippet[:2] + [\"...\"] + snippet[-2:] if len(snippet) > 4 else snippet\n",
    "\n",
    "            all_blocks.append({\n",
    "                \"catalog\": CATALOG_DATE,\n",
    "                \"college\": college,\n",
    "                \"degree\": degree_name,\n",
    "                \"start\": start_idx,\n",
    "                \"stop\": stop_idx,\n",
    "                \"length\": block_len,\n",
    "                \"preview\": preview\n",
    "            })\n",
    "\n",
    "# === Sort blocks ===\n",
    "shortest_blocks = sorted(all_blocks, key=lambda x: x[\"length\"])[:N]\n",
    "longest_blocks = sorted(all_blocks, key=lambda x: x[\"length\"], reverse=True)[:N]\n",
    "\n",
    "# === Show ===\n",
    "print(f\"\\nðŸ“Œ Shortest {N} Degree blocks:\\n\")\n",
    "for block in shortest_blocks:\n",
    "    print(f\"{block['catalog']} | {block['college']} | {block['degree']}\")\n",
    "    print(f\"  Lines: {block['start']}â€“{block['stop']} ({block['length']} lines)\")\n",
    "    for p in block['preview']:\n",
    "        print(f\"    {p}\")\n",
    "    print()\n",
    "\n",
    "print(f\"\\nðŸ“Œ Longest {N} Degree blocks:\\n\")\n",
    "for block in longest_blocks:\n",
    "    print(f\"{block['catalog']} | {block['college']} | {block['degree']}\")\n",
    "    print(f\"  Lines: {block['start']}â€“{block['stop']} ({block['length']} lines)\")\n",
    "    for p in block['preview']:\n",
    "        print(f\"    {p}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\nâœ… Global spot check complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a3057-043f-412c-b5ed-3c3cc3f25b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abefb488-8516-4421-9f49-caff34521abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Batch parse all catalogs â€” CCN, CODE, fallback â€” combine all valid & anomalies, show sorted unique\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "# === CONFIG ===\n",
    "INPUT_DIR = \"../WGU_catalog/catalogs/plumber_parsed/\"\n",
    "\n",
    "# Anchors\n",
    "ANCHOR_CCN_HEADER = re.compile(r'^CCN\\s+Course Number\\s+Course Description\\s+CUs\\s+Term', re.I)\n",
    "ANCHOR_TOTAL_CUS = re.compile(r'^Total CUs', re.I)\n",
    "ANCHOR_FOOTER_COPYRIGHT = re.compile(r'Â© Western Governors University', re.I)\n",
    "\n",
    "# Regex patterns\n",
    "ccn_pattern = re.compile(r'^([A-Z]{2,5})\\s+(\\d{1,4})\\s+([A-Z0-9]{2,5})\\s+(.+?)\\s+(\\d+)\\s+(\\d+)$')\n",
    "code_pattern = re.compile(r'^([A-Z0-9]{1,6})\\s+(.+?)\\s+(\\d+)\\s+(\\d+)$')\n",
    "fallback_pattern = re.compile(r'^(.+?)\\s+(\\d+)\\s+(\\d+)$')\n",
    "\n",
    "# === Combined containers ===\n",
    "all_valid_rows = []\n",
    "all_anomalies = []\n",
    "\n",
    "# === Process all .txt files ===\n",
    "for filename in sorted(os.listdir(INPUT_DIR)):\n",
    "    if not filename.endswith('.txt'):\n",
    "        continue\n",
    "\n",
    "    FILE_PATH = os.path.join(INPUT_DIR, filename)\n",
    "    print(f\"\\nðŸ“˜ Processing: {filename}\")\n",
    "\n",
    "    # === Load lines ===\n",
    "    with open(FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        lines = [l.strip() for l in f]\n",
    "\n",
    "    # === Find first CCN header ===\n",
    "    first_ccn_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if ANCHOR_CCN_HEADER.search(line):\n",
    "            first_ccn_idx = i\n",
    "            break\n",
    "\n",
    "    if first_ccn_idx is None:\n",
    "        print(\"âš ï¸  No CCN header found, skipping.\")\n",
    "        continue\n",
    "\n",
    "    lines_to_scan = lines[first_ccn_idx:]\n",
    "    ccn_indices = [i for i, line in enumerate(lines_to_scan) if ANCHOR_CCN_HEADER.search(line)]\n",
    "    print(f\"  CCN tables found: {len(ccn_indices)}\")\n",
    "\n",
    "    # === Extract raw rows ===\n",
    "    raw_course_rows = []\n",
    "\n",
    "    for idx, anchor_idx in enumerate(ccn_indices):\n",
    "        block_start = anchor_idx + 1\n",
    "        block_end = len(lines_to_scan)\n",
    "\n",
    "        if idx + 1 < len(ccn_indices):\n",
    "            block_end = ccn_indices[idx + 1]\n",
    "\n",
    "        for i in range(block_start, block_end):\n",
    "            line = lines_to_scan[i]\n",
    "            if ANCHOR_TOTAL_CUS.search(line) or ANCHOR_FOOTER_COPYRIGHT.search(line):\n",
    "                block_end = i\n",
    "                break\n",
    "\n",
    "        for i in range(block_start, block_end):\n",
    "            raw_line = lines_to_scan[i].strip()\n",
    "            if raw_line:\n",
    "                raw_course_rows.append(raw_line)\n",
    "\n",
    "    print(f\"  Raw rows pulled: {len(raw_course_rows)}\")\n",
    "\n",
    "    # === Classify with fallback ===\n",
    "    for row in raw_course_rows:\n",
    "        if ccn_pattern.match(row):\n",
    "            all_valid_rows.append(f\"[CCN_FULL] {row}\")\n",
    "        elif code_pattern.match(row):\n",
    "            all_valid_rows.append(f\"[CODE_ONLY] {row}\")\n",
    "        else:\n",
    "            m = fallback_pattern.match(row)\n",
    "            if m:\n",
    "                title = m.group(1)\n",
    "                cus = m.group(2)\n",
    "                term = m.group(3)\n",
    "                parens = re.search(r'\\(([^)]+)\\)', title)\n",
    "                if parens:\n",
    "                    code = parens.group(1)\n",
    "                    title_clean = title.replace(f\"({code})\", \"\").strip()\n",
    "                    all_valid_rows.append(f\"[FALLBACK+PARENS:{code}] {title_clean} {cus} {term}\")\n",
    "                else:\n",
    "                    all_valid_rows.append(f\"[FALLBACK] {title} {cus} {term}\")\n",
    "            else:\n",
    "                all_anomalies.append(row)\n",
    "\n",
    "# === Dedup + sort ===\n",
    "valid_combined = sorted(set(all_valid_rows), key=len)\n",
    "anomalies_combined = sorted(\n",
    "    [a for a in set(all_anomalies) if \"Total CUs\" not in a],\n",
    "    key=len\n",
    ")\n",
    "\n",
    "# === Final output ===\n",
    "print(f\"\\nâœ… COMBINED valid rows (unique): {len(valid_combined)}\\n\")\n",
    "for row in valid_combined:\n",
    "    print(row)\n",
    "\n",
    "print(f\"\\nâŒ COMBINED anomalies (unique, no 'Total CUs'): {len(anomalies_combined)}\\n\")\n",
    "for row in anomalies_combined:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6046c66e-3dbc-4872-aa25-8582d61e226a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264a5c65-609d-4a5f-8b17-4bcf1f2ff735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43410d36-0e40-48a1-8389-7aa7a9b8365e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2c70b1a-6627-4744-8e50-c7197df8577f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226812ca-fcbc-4210-abd7-b7f944c8f4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da492061-9f6d-4644-912f-8578ad01dc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411dce65-aefb-47dd-9d41-5426e90034f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0458526b-54e7-422a-b3c2-9905e2d9a568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbf579b-b293-45a0-9a58-c3c2ceba1465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a04ea2-6829-48e9-8942-634ea48c6327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc9dafc-e982-4151-b2b0-02b0e54517de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6227dfaa-7f21-4128-965a-a2e8cb006057",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Next Phase: Degree â†’ Course Block Parsing Plan (V10)\n",
    "\n",
    "This section implements the **V10 Degree â†’ Course pipeline** with strict controls:\n",
    "\n",
    "- **Input:** Verified Colleges from `colleges_reference_v10.json` and trusted Degree boundaries from `degree_snapshots_v10_seed.json`  \n",
    "- **Goal:** Fence each Degree block within its College section using the locked snapshot, map start and stop lines, and verify CCN anchors appear only within valid Degree bounds.\n",
    "\n",
    "### Key Steps\n",
    "\n",
    "1ï¸âƒ£ **Locate Degree Boundaries:**  \n",
    "   - Degree block start and stop lines come directly from `degree_snapshots_v10_seed.json`.  \n",
    "   - If forced anchors are needed (e.g., `Total CUs` footers or embedded disclaimers), they must be versioned and documented in `catalog_schema_notes_v10.md`.\n",
    "\n",
    "2ï¸âƒ£ **Extract Degree Blocks:**  \n",
    "   - For each fenced Degree block, confirm at least one valid CCN table exists.  \n",
    "   - Hard fail on any orphan CCN block or stray Course row outside defined Degree fences.\n",
    "\n",
    "3ï¸âƒ£ **Unit Tests:**  \n",
    "   - Validate edge cases with mid-degree narrative text, disclaimers, or inline section disclaimers.  \n",
    "   - Confirm no Degree block overlaps, floats, or appears in multiple Colleges.\n",
    "\n",
    "4ï¸âƒ£ **Output:**  \n",
    "   - Verified `degree_snapshots_v10.json` containing `{College â†’ Degree â†’ [start_line, stop_line]}` for every catalog.  \n",
    "   - This snapshot is the trusted fence for Course row parsing and cannot drift silently.\n",
    "\n",
    "âœ… **Standing Truth:** No Degree â†’ Course block merges quietly. Any forced pins or exceptions must be versioned and logged in `catalog_schema_notes_v10.md`.  \n",
    "This ensures the final `Course` index is fully auditable, isolated, and repeatable under V10 controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b5d09f-2840-407e-a7eb-4183ae05d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# === Anchors & Patterns ===\n",
    "ANCHOR_DEGREE_HEADER = re.compile(r\"^(Bachelor|Master|Certificate|Post|Endorsement|MBA|MS,|BS,)\")\n",
    "ANCHOR_CCN_HEADER = re.compile(r\"CCN.*Course Number\", re.IGNORECASE)\n",
    "ANCHOR_COURSE_ROW = re.compile(r\"^[A-Z]{2,4}\\s+\\d{4}\")\n",
    "ANCHOR_TOTAL_CUS = re.compile(r\"Total CUs\", re.IGNORECASE)\n",
    "ANCHOR_COPYRIGHT = re.compile(r\"Â©\")\n",
    "\n",
    "# === CONFIG ===\n",
    "CATALOG_DATE = \"2017-01\"\n",
    "FILE_PATH = \"../WGU_catalog/catalogs/plumber_parsed/catalog_2017_01.txt\"\n",
    "SECTIONS_INDEX_PATH = \"./sections_index_v10.json\"\n",
    "\n",
    "# === Load verified College â†’ Degree structure ===\n",
    "with open(SECTIONS_INDEX_PATH, \"r\") as f:\n",
    "    sections_index = json.load(f)\n",
    "\n",
    "# === Load text ===\n",
    "with open(FILE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = [line.strip() for line in f]\n",
    "\n",
    "# === Build result container ===\n",
    "output = []\n",
    "\n",
    "# === Process each College ===\n",
    "for college, degrees in sections_index.items():\n",
    "    for degree_name in degrees:\n",
    "        # 1ï¸âƒ£ Find Degree start\n",
    "        degree_start = None\n",
    "        for i, line in enumerate(lines):\n",
    "            if line == degree_name:\n",
    "                degree_start = i\n",
    "                break\n",
    "        if degree_start is None:\n",
    "            raise ValueError(f\"Degree header not found: {degree_name}\")\n",
    "\n",
    "        # 2ï¸âƒ£ Find Degree stop\n",
    "        degree_stop = len(lines)\n",
    "        for j in range(degree_start + 1, len(lines)):\n",
    "            next_line = lines[j]\n",
    "            if ANCHOR_DEGREE_HEADER.match(next_line) and next_line != degree_name:\n",
    "                degree_stop = j\n",
    "                break\n",
    "\n",
    "        # 3ï¸âƒ£ Fence Degree block\n",
    "        degree_block = lines[degree_start:degree_stop]\n",
    "\n",
    "        # 4ï¸âƒ£ Find CCN blocks within Degree block\n",
    "        ccn_starts = []\n",
    "        for idx, line in enumerate(degree_block):\n",
    "            if ANCHOR_CCN_HEADER.search(line):\n",
    "                ccn_starts.append(idx)\n",
    "\n",
    "        if not ccn_starts:\n",
    "            raise ValueError(f\"No CCN table found for {degree_name}\")\n",
    "\n",
    "        courses = []\n",
    "        for start_idx in ccn_starts:\n",
    "            for k in range(start_idx + 1, len(degree_block)):\n",
    "                line = degree_block[k]\n",
    "\n",
    "                # Fence: stop at footer\n",
    "                if ANCHOR_TOTAL_CUS.search(line) or ANCHOR_COPYRIGHT.search(line):\n",
    "                    break\n",
    "\n",
    "                # Extract valid course rows only\n",
    "                if ANCHOR_COURSE_ROW.match(line):\n",
    "                    tokens = line.split()\n",
    "                    if len(tokens) < 5:\n",
    "                        continue  # suspicious row\n",
    "\n",
    "                    # Example: BUS 2100 C711 Intro 3 1\n",
    "                    prefix = tokens[0]\n",
    "                    number = tokens[1]\n",
    "                    catalog_code = tokens[2]\n",
    "                    title = \" \".join(tokens[3:-2])\n",
    "                    cus = tokens[-2]\n",
    "                    term = tokens[-1]\n",
    "\n",
    "                    courses.append({\n",
    "                        \"prefix\": prefix,\n",
    "                        \"number\": number,\n",
    "                        \"catalog_code\": catalog_code,\n",
    "                        \"title\": title,\n",
    "                        \"cus\": cus,\n",
    "                        \"term\": term\n",
    "                    })\n",
    "\n",
    "        output.append({\n",
    "            \"college\": college,\n",
    "            \"degree\": degree_name,\n",
    "            \"courses\": courses\n",
    "        })\n",
    "\n",
    "print(\"\\nâœ… Courses extracted for catalog_2017_01.txt\\n\")\n",
    "for block in output:\n",
    "    print(f\"{block['college']} | {block['degree']} | Courses: {len(block['courses'])}\")\n",
    "\n",
    "# === Save snapshot ===\n",
    "with open(\"course_index_v10.json\", \"w\") as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(\"\\nðŸ“ course_index_v10.json written. Review for any drift or orphans.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eca55b1-3560-492a-a462-ca652b5792e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07683cd9-9a02-452b-b1a5-7c181f6a5e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (WGU)",
   "language": "python",
   "name": "wgu-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
