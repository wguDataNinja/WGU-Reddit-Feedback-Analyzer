== stage1_classifier.py ==
from __future__ import annotations

"""
Stage 1 classifier.

Loads prompt templates, formats inputs, calls generate(), parses JSON output,
and validates predictions with Pydantic.

Implements safe_parse_stage1_response and surfaces all schema/parse issues as
contains_painpoint="u" plus error flags. The classify_post function is the
primary entry point used by the Stage 1 benchmark runner.
"""

import json
import re
from pathlib import Path

from pydantic import ValidationError

from wgu_reddit_analyzer.benchmark.stage1_types import (
    Stage1PredictionInput,
    Stage1PredictionOutput,
    LlmCallResult,
)
from wgu_reddit_analyzer.benchmark.model_client import generate
from wgu_reddit_analyzer.utils.logging_utils import get_logger

logger = get_logger("benchmark.stage1_classifier")


def load_prompt_template(path: str | Path) -> str:
    """Load a prompt template from disk."""
    p = Path(path)
    return p.read_text(encoding="utf-8")


def build_prompt(template: str, example: Stage1PredictionInput) -> str:
    """
    Render a prompt template for a single post.

    Uses simple replacement so JSON braces in the template are not
    treated as format fields.
    """
    return (
        template.replace("{post_id}", example.post_id)
        .replace("{course_code}", example.course_code)
        .replace("{post_text}", example.text)
    )


def _strip_code_fences(text: str) -> str:
    s = text.strip()
    if s.startswith("```"):
        lines = s.splitlines()
        lines = lines[1:]
        if lines and lines[-1].strip().startswith("```"):
            lines = lines[:-1]
        s = "\n".join(lines).strip()
    return s


def _extract_json_block(text: str) -> str:
    """
    Best-effort extraction of the main JSON object from the model output.

    Strips code fences and trims to the outermost {...} block. If no
    braces are found, returns the original text.
    """
    s = _strip_code_fences(text)

    start = s.find("{")
    end = s.rfind("}")
    if start != -1 and end != -1 and end > start:
        return s[start : end + 1]
    return s


def _regex_contains_painpoint(text: str) -> tuple[str | None, bool]:
    """
    Try to extract an unambiguous y/n/u from a contains_painpoint field.

    Returns (label, ambiguous_flag).
    """
    pattern = r'"contains_painpoint"\s*:\s*"([ynu])"'
    matches = re.findall(pattern, text, flags=re.IGNORECASE)

    if not matches:
        return None, False

    distinct = {m.lower() for m in matches}
    if len(distinct) == 1:
        return distinct.pop(), False

    return None, True


def safe_parse_stage1_response(
    raw_text: str,
) -> tuple[str, str, str, float, bool, bool, bool]:
    """
    Safe parsing for Stage 1 responses.

    Returns:
        contains_painpoint (str: y/n/u)
        root_cause_summary (str)
        pain_point_snippet (str)
        confidence (float)
        parse_error (bool)
        schema_error (bool)
        used_fallback (bool)
    """
    parse_error = False
    schema_error = False
    used_fallback = False

    json_text = _extract_json_block(raw_text)

    # Strict JSON parse path
    try:
        data = json.loads(json_text)

== stage1_types.py ==
from __future__ import annotations
"""
Typed data structures used by Stage 1 benchmarking.

Defines the input format sent to the LLM, the normalized prediction returned
from the LLM, and the metadata collected for each model call. These types
provide a stable interface for all Stage 1 code.
"""

from typing import Literal
from pydantic import BaseModel


class Stage1PredictionInput(BaseModel):
    """Single post input to the Stage 1 classifier."""
    post_id: str
    course_code: str
    text: str  # usually "title\n\nselftext"


class Stage1PredictionOutput(BaseModel):
    """Normalized Stage 1 prediction and parse flags."""
    post_id: str
    course_code: str

    # Core decision
    contains_painpoint: Literal["y", "n", "u"]

    # Only meaningful when contains_painpoint == "y"
    root_cause_summary: str = ""
    pain_point_snippet: str = ""

    # Confidence in [0.0, 1.0]
    confidence: float = 0.0

    # Raw model output
    raw_response: str

    # Error / parsing flags
    parse_error: bool = False
    schema_error: bool = False
    used_fallback: bool = False


class LlmCallResult(BaseModel):
    """
    Metadata for a single LLM call.

    Captures low-level details needed for cost, latency, and failure
    analysis. Everything inside here should be provider-agnostic.
    """
    model_name: str
    provider: str
    raw_text: str
    input_tokens: int
    output_tokens: int
    total_cost_usd: float
    elapsed_sec: float

    # Failure / retry metadata
    llm_failure: bool = False
    num_retries: int = 0
    error_message: str | None = None
    timeout_sec: float | None = None

    # Timing metadata
    started_at: float | None = None
    finished_at: float | None = None
== preprocess_painpoints.py ==
#!/usr/bin/env python3
"""
Prepare a token-conscious painpoint table from full-corpus Stage-1 predictions.

Adds:
    - Sorting by number of posts per course (descending)
    - Stable tie-break on course_code, then post_id

Input:
    /Users/buddy/Desktop/WGU-Reddit/artifacts/stage1/full_corpus/.../predictions_FULL.csv

Output (example):
    /Users/buddy/Desktop/WGU-Reddit/artifacts/stage2/painpoints_full_for_clustering.csv

Keeps only:
    - pred_contains_painpoint == "y"
    - no parse/schema/fallback/llm failures
    - confidence_pred >= MIN_CONFIDENCE

Output columns:
    - post_id
    - course_code
    - root_cause_summary
    - pain_point_snippet
"""

import csv
from collections import defaultdict
from pathlib import Path

# --- CONFIG ---------------------------------------------------------

DEFAULT_INPUT = Path(
    "/Users/buddy/Desktop/WGU-Reddit/artifacts/stage1/full_corpus/"
    "gpt-5-mini_s1_optimal_fullcorpus_20251126_023336/"
    "predictions_FULL.csv"
)

DEFAULT_OUTPUT = Path(
    "/Users/buddy/Desktop/WGU-Reddit/artifacts/stage2/painpoints_llm_friendly.csv"
)

MIN_CONFIDENCE = 0.50


# --- SCRIPT ---------------------------------------------------------

def prepare_painpoints(
    input_csv: Path = DEFAULT_INPUT,
    output_csv: Path = DEFAULT_OUTPUT,
    min_conf: float = MIN_CONFIDENCE,
) -> None:

    output_csv.parent.mkdir(parents=True, exist_ok=True)

    painpoints = []
    total = 0

    with input_csv.open("r", newline="", encoding="utf-8") as f_in:
        reader = csv.DictReader(f_in)

        for row in reader:
            total += 1

            if row.get("pred_contains_painpoint") != "y":
                continue

            if any(
                row.get(flag, "False") == "True"
                for flag in ("parse_error", "schema_error", "used_fallback", "llm_failure")
            ):
                continue

            try:
                conf = float(row.get("confidence_pred", "0") or 0.0)
            except ValueError:
                conf = 0.0

            if conf < min_conf:
                continue

            post_id = row["post_id"]
            course_code = row["course_code"]
            root_cause = (row.get("root_cause_summary_pred") or "").strip()
            snippet = (row.get("pain_point_snippet_pred") or "").strip()

            painpoints.append(
                {
                    "post_id": post_id,
                    "course_code": course_code,
                    "root_cause_summary": root_cause,
                    "pain_point_snippet": snippet,
                }
            )

    # --- SORT: by number of posts per course (desc), then course_code, then post_id --

    course_post_ids = defaultdict(set)
    for p in painpoints:
        course_post_ids[p["course_code"]].add(p["post_id"])

    painpoints.sort(
        key=lambda r: (
            -len(course_post_ids[r["course_code"]]),  # more posts first
            r["course_code"],
            r["post_id"],
        )
    )

    # --- WRITE OUTPUT ----------------------------------------------
    with output_csv.open("w", newline="", encoding="utf-8") as f_out:
        fieldnames = [
            "post_id",
            "course_code",
            "root_cause_summary",
            "pain_point_snippet",
        ]
        writer = csv.DictWriter(f_out, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(painpoints)

== build_analytics.py ==
"""
Build the report_data layer for WGU Reddit Analyzer.

This script merges Stage 0, Stage 2, and Stage 3 artifacts plus course metadata
into a small set of clean tables under artifacts/report_data/, which power
human-facing reports and any future site/GUI.

Outputs (all unfiltered, full data):

- artifacts/report_data/post_master.csv
- artifacts/report_data/course_summary.csv
- artifacts/report_data/course_cluster_detail.jsonl
- artifacts/report_data/global_issues.csv
- artifacts/report_data/issue_course_matrix.csv
"""

from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import List, Dict, Any

import pandas as pd


# ---------------------------------------------------------------------------
# Path helpers
# ---------------------------------------------------------------------------

def project_root() -> Path:
    """Return the repo root (one level above src/)."""
    return Path(__file__).resolve().parents[3]


def ensure_dir(path: Path) -> None:
    """Create directory if it does not already exist."""
    path.mkdir(parents=True, exist_ok=True)


# ---------------------------------------------------------------------------
# Loaders
# ---------------------------------------------------------------------------

def load_stage0_filtered(artifacts_dir: Path) -> pd.DataFrame:
    """Load the locked Stage 0 filtered posts."""
    path = artifacts_dir / "stage0_filtered_posts.jsonl"
    if not path.exists():
        raise FileNotFoundError(f"Missing Stage 0 file: {path}")
    df = pd.read_json(path, lines=True)
    if "post_id" not in df.columns:
        raise ValueError("stage0_filtered_posts.jsonl missing 'post_id'")
    return df


def load_painpoints_stage2(artifacts_dir: Path) -> pd.DataFrame:
    """Load Stage 2 pain point classifier outputs."""
    path = artifacts_dir / "stage2" / "painpoints_llm_friendly.csv"
    if not path.exists():
        raise FileNotFoundError(f"Missing Stage 2 painpoint file: {path}")
    df = pd.read_csv(path)
    required_cols = {"post_id", "course_code", "root_cause_summary", "pain_point_snippet"}
    missing = required_cols - set(df.columns)
    if missing:
        raise ValueError(f"Stage 2 painpoint file missing columns: {missing}")
    return df


def load_stage3_preprocessed(preprocessed_dir: Path) -> pd.DataFrame:
    """Load Stage 2/3 preprocessed clusters (clusters_llm.csv)."""
    path = preprocessed_dir / "clusters_llm.csv"
    if not path.exists():
        raise FileNotFoundError(f"Missing clusters_llm.csv in {preprocessed_dir}")
    df = pd.read_csv(path)
    required_cols = {"cluster_id", "issue_summary", "course_code", "course_title", "num_posts"}
    missing = required_cols - set(df.columns)
    if missing:
        raise ValueError(f"clusters_llm.csv missing columns: {missing}")
    return df


def load_stage3_runs(run_dir: Path) -> Dict[str, Any]:
    """
    Load Stage 3 global clustering outputs:
    - cluster_global_index.csv
    - post_global_index.csv
    - global_clusters.json
    """
    cluster_global_path = run_dir / "cluster_global_index.csv"
    post_global_path = run_dir / "post_global_index.csv"
    global_clusters_path = run_dir / "global_clusters.json"

    for p in [cluster_global_path, post_global_path, global_clusters_path]:
        if not p.exists():
            raise FileNotFoundError(f"Missing Stage 3 file: {p}")

    df_cluster_global = pd.read_csv(cluster_global_path)
    df_post_global = pd.read_csv(post_global_path)
    with global_clusters_path.open("r", encoding="utf-8") as f:
        global_clusters = json.load(f)

    return {
        "cluster_global": df_cluster_global,
        "post_global": df_post_global,
        "global_clusters_raw": global_clusters,
    }


def load_course_metadata(data_dir: Path) -> pd.DataFrame:
    """Load course metadata (code, title, college)."""
    path = data_dir / "course_list_with_college.csv"
    if not path.exists():
        raise FileNotFoundError(f"Missing course metadata file: {path}")
    df = pd.read_csv(path)
    required_cols = {"CourseCode", "Title", "Colleges"}
    missing = required_cols - set(df.columns)
    if missing:
        raise ValueError(f"course_list_with_college.csv missing columns: {missing}")
    return df

